{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00007\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030375f375f62617463685f73697a653d3132382c636c69705f72616e67653d302e323137372c656e745f636f65663d302e303030392c6761655f6c616d6264613d302e393532382c67616d6d613d302e393932322c6c6561726e696e675f726174653d302e303030302c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 2.813147070329732e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9921516904231243,\n    \"gae_lambda\": 0.9528281344912943,\n    \"clip_range\": 0.21766914901215625,\n    \"ent_coef\": 0.0008848282633930527,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 2.813147070329732e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9921516904231243,\n    \"gae_lambda\": 0.9528281344912943,\n    \"clip_range\": 0.21766914901215625,\n    \"ent_coef\": 0.0008848282633930527,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 2.813147070329732e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9921516904231243,\n    \"gae_lambda\": 0.9528281344912943,\n    \"clip_range\": 0.21766914901215625,\n    \"ent_coef\": 0.0008848282633930527\n  },\n  \"experiment_tag\": \"7_batch_size=128,clip_range=0.2177,ent_coef=0.0009,gae_lambda=0.9528,gamma=0.9922,learning_rate=0.0000,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00007_7_batch_size=128,clip_range=0.2177,ent_coef=0.0009,gae_lambda=0.9528,gamma=0.9922,learning_rate=0.0000,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205966.907918,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -230.08964952589446,\n    \"timestamp\": 1762206074,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00007\",\n    \"date\": \"2025-11-03_15-41-14\",\n    \"time_this_iter_s\": 107.48719811439514,\n    \"time_total_s\": 107.48719811439514,\n    \"pid\": 96134,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 2.813147070329732e-05,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9921516904231243,\n      \"gae_lambda\": 0.9528281344912943,\n      \"clip_range\": 0.21766914901215625,\n      \"ent_coef\": 0.0008848282633930527,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 107.48719811439514,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_batch_size=128,clip_range=0.2177,ent_coef=0.0009,gae_lambda=0.9528,gamma=0.9922,learning_rate=0.0000,n_steps=1024\"\n  },\n  \"last_result_time\": 1762206074.397734,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -230.08964952589446,\n      \"min\": -230.08964952589446,\n      \"avg\": -230.08964952589446,\n      \"last\": -230.08964952589446,\n      \"last-5-avg\": -230.08964952589446,\n      \"last-10-avg\": -230.08964952589446\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 107.48719811439514,\n      \"min\": 107.48719811439514,\n      \"avg\": 107.48719811439514,\n      \"last\": 107.48719811439514,\n      \"last-5-avg\": 107.48719811439514,\n      \"last-10-avg\": 107.48719811439514\n    },\n    \"time_total_s\": {\n      \"max\": 107.48719811439514,\n      \"min\": 107.48719811439514,\n      \"avg\": 107.48719811439514,\n      \"last\": 107.48719811439514,\n      \"last-5-avg\": 107.48719811439514,\n      \"last-10-avg\": 107.48719811439514\n    },\n    \"time_since_restore\": {\n      \"max\": 107.48719811439514,\n      \"min\": 107.48719811439514,\n      \"avg\": 107.48719811439514,\n      \"last\": 107.48719811439514,\n      \"last-5-avg\": 107.48719811439514,\n      \"last-10-avg\": 107.48719811439514\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c06cc2de68aeba32612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c06cc2de68aeba32612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405adf2e41000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405adf2e41000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405adf2e41000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405adf2e41000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405adf2e41000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405adf2e41000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00009\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030395f395f62617463685f73697a653d3132382c636c69705f72616e67653d302e333030302c656e745f636f65663d302e303030322c6761655f6c616d6264613d302e393537302c67616d6d613d302e393934302c6c6561726e696e675f726174653d302e303030312c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00010302572224765742,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9939872669491973,\n    \"gae_lambda\": 0.9570422668456817,\n    \"clip_range\": 0.2999644476073371,\n    \"ent_coef\": 0.0001638187412666621,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00010302572224765742,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9939872669491973,\n    \"gae_lambda\": 0.9570422668456817,\n    \"clip_range\": 0.2999644476073371,\n    \"ent_coef\": 0.0001638187412666621,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00010302572224765742,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9939872669491973,\n    \"gae_lambda\": 0.9570422668456817,\n    \"clip_range\": 0.2999644476073371,\n    \"ent_coef\": 0.0001638187412666621\n  },\n  \"experiment_tag\": \"9_batch_size=128,clip_range=0.3000,ent_coef=0.0002,gae_lambda=0.9570,gamma=0.9940,learning_rate=0.0001,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00009_9_batch_size=128,clip_range=0.3000,ent_coef=0.0002,gae_lambda=0.9570,gamma=0.9940,learning_rate=0.0001,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762206037.740124,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 3.932670622365606,\n    \"timestamp\": 1762206145,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00009\",\n    \"date\": \"2025-11-03_15-42-25\",\n    \"time_this_iter_s\": 107.4376380443573,\n    \"time_total_s\": 107.4376380443573,\n    \"pid\": 96165,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00010302572224765742,\n      \"n_steps\": 512,\n      \"batch_size\": 128,\n      \"gamma\": 0.9939872669491973,\n      \"gae_lambda\": 0.9570422668456817,\n      \"clip_range\": 0.2999644476073371,\n      \"ent_coef\": 0.0001638187412666621,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 107.4376380443573,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_batch_size=128,clip_range=0.3000,ent_coef=0.0002,gae_lambda=0.9570,gamma=0.9940,learning_rate=0.0001,n_steps=512\"\n  },\n  \"last_result_time\": 1762206145.180429,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 3.932670622365606,\n      \"min\": 3.932670622365606,\n      \"avg\": 3.932670622365606,\n      \"last\": 3.932670622365606,\n      \"last-5-avg\": 3.932670622365606,\n      \"last-10-avg\": 3.932670622365606\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 107.4376380443573,\n      \"min\": 107.4376380443573,\n      \"avg\": 107.4376380443573,\n      \"last\": 107.4376380443573,\n      \"last-5-avg\": 107.4376380443573,\n      \"last-10-avg\": 107.4376380443573\n    },\n    \"time_total_s\": {\n      \"max\": 107.4376380443573,\n      \"min\": 107.4376380443573,\n      \"avg\": 107.4376380443573,\n      \"last\": 107.4376380443573,\n      \"last-5-avg\": 107.4376380443573,\n      \"last-10-avg\": 107.4376380443573\n    },\n    \"time_since_restore\": {\n      \"max\": 107.4376380443573,\n      \"min\": 107.4376380443573,\n      \"avg\": 107.4376380443573,\n      \"last\": 107.4376380443573,\n      \"last-5-avg\": 107.4376380443573,\n      \"last-10-avg\": 107.4376380443573\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447400f761c03e80080612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447400f761c03e80080612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405adc0243000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405adc0243000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405adc0243000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405adc0243000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405adc0243000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405adc0243000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00004\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030345f345f62617463685f73697a653d3132382c636c69705f72616e67653d302e313935312c656e745f636f65663d302e303030312c6761655f6c616d6264613d302e393635342c67616d6d613d302e393834342c6c6561726e696e675f726174653d302e303030312c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 5.760066665154113e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9844218613887803,\n    \"gae_lambda\": 0.9654016000442807,\n    \"clip_range\": 0.19508560851103918,\n    \"ent_coef\": 7.121385194196828e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 5.760066665154113e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9844218613887803,\n    \"gae_lambda\": 0.9654016000442807,\n    \"clip_range\": 0.19508560851103918,\n    \"ent_coef\": 7.121385194196828e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 5.760066665154113e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9844218613887803,\n    \"gae_lambda\": 0.9654016000442807,\n    \"clip_range\": 0.19508560851103918,\n    \"ent_coef\": 7.121385194196828e-05\n  },\n  \"experiment_tag\": \"4_batch_size=128,clip_range=0.1951,ent_coef=0.0001,gae_lambda=0.9654,gamma=0.9844,learning_rate=0.0001,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00004_4_batch_size=128,clip_range=0.1951,ent_coef=0.0001,gae_lambda=0.9654,gamma=0.9844,learning_rate=0.0001,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205927.894871,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -56.73478710879143,\n    \"timestamp\": 1762206033,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00004\",\n    \"date\": \"2025-11-03_15-40-33\",\n    \"time_this_iter_s\": 105.86147785186768,\n    \"time_total_s\": 105.86147785186768,\n    \"pid\": 96112,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5.760066665154113e-05,\n      \"n_steps\": 512,\n      \"batch_size\": 128,\n      \"gamma\": 0.9844218613887803,\n      \"gae_lambda\": 0.9654016000442807,\n      \"clip_range\": 0.19508560851103918,\n      \"ent_coef\": 7.121385194196828e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 105.86147785186768,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_batch_size=128,clip_range=0.1951,ent_coef=0.0001,gae_lambda=0.9654,gamma=0.9844,learning_rate=0.0001,n_steps=512\"\n  },\n  \"last_result_time\": 1762206033.758913,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -56.73478710879143,\n      \"min\": -56.73478710879143,\n      \"avg\": -56.73478710879143,\n      \"last\": -56.73478710879143,\n      \"last-5-avg\": -56.73478710879143,\n      \"last-10-avg\": -56.73478710879143\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 105.86147785186768,\n      \"min\": 105.86147785186768,\n      \"avg\": 105.86147785186768,\n      \"last\": 105.86147785186768,\n      \"last-5-avg\": 105.86147785186768,\n      \"last-10-avg\": 105.86147785186768\n    },\n    \"time_total_s\": {\n      \"max\": 105.86147785186768,\n      \"min\": 105.86147785186768,\n      \"avg\": 105.86147785186768,\n      \"last\": 105.86147785186768,\n      \"last-5-avg\": 105.86147785186768,\n      \"last-10-avg\": 105.86147785186768\n    },\n    \"time_since_restore\": {\n      \"max\": 105.86147785186768,\n      \"min\": 105.86147785186768,\n      \"avg\": 105.86147785186768,\n      \"last\": 105.86147785186768,\n      \"last-5-avg\": 105.86147785186768,\n      \"last-10-avg\": 105.86147785186768\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c04c5e0d8104e40b612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c04c5e0d8104e40b612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a772274000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a772274000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a772274000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a772274000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a772274000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a772274000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00002\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030325f325f62617463685f73697a653d3235362c636c69705f72616e67653d302e323936342c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393533362c67616d6d613d302e393930362c6c6561726e696e675f726174653d302e303030332c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00031837037330898784,\n    \"n_steps\": 2048,\n    \"batch_size\": 256,\n    \"gamma\": 0.9906203640324278,\n    \"gae_lambda\": 0.9535919942603173,\n    \"clip_range\": 0.29641449174359863,\n    \"ent_coef\": 2.2211844897048827e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00031837037330898784,\n    \"n_steps\": 2048,\n    \"batch_size\": 256,\n    \"gamma\": 0.9906203640324278,\n    \"gae_lambda\": 0.9535919942603173,\n    \"clip_range\": 0.29641449174359863,\n    \"ent_coef\": 2.2211844897048827e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00031837037330898784,\n    \"n_steps\": 2048,\n    \"batch_size\": 256,\n    \"gamma\": 0.9906203640324278,\n    \"gae_lambda\": 0.9535919942603173,\n    \"clip_range\": 0.29641449174359863,\n    \"ent_coef\": 2.2211844897048827e-05\n  },\n  \"experiment_tag\": \"2_batch_size=256,clip_range=0.2964,ent_coef=0.0000,gae_lambda=0.9536,gamma=0.9906,learning_rate=0.0003,n_steps=2048\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00002_2_batch_size=256,clip_range=0.2964,ent_coef=0.0000,gae_lambda=0.9536,gamma=0.9906,learning_rate=0.0003,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205827.465835,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -83.23168817819185,\n    \"timestamp\": 1762205926,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00002\",\n    \"date\": \"2025-11-03_15-38-46\",\n    \"time_this_iter_s\": 98.6942458152771,\n    \"time_total_s\": 98.6942458152771,\n    \"pid\": 96055,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00031837037330898784,\n      \"n_steps\": 2048,\n      \"batch_size\": 256,\n      \"gamma\": 0.9906203640324278,\n      \"gae_lambda\": 0.9535919942603173,\n      \"clip_range\": 0.29641449174359863,\n      \"ent_coef\": 2.2211844897048827e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 98.6942458152771,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_batch_size=256,clip_range=0.2964,ent_coef=0.0000,gae_lambda=0.9536,gamma=0.9906,learning_rate=0.0003,n_steps=2048\"\n  },\n  \"last_result_time\": 1762205926.162943,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -83.23168817819185,\n      \"min\": -83.23168817819185,\n      \"avg\": -83.23168817819185,\n      \"last\": -83.23168817819185,\n      \"last-5-avg\": -83.23168817819185,\n      \"last-10-avg\": -83.23168817819185\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 98.6942458152771,\n      \"min\": 98.6942458152771,\n      \"avg\": 98.6942458152771,\n      \"last\": 98.6942458152771,\n      \"last-5-avg\": 98.6942458152771,\n      \"last-10-avg\": 98.6942458152771\n    },\n    \"time_total_s\": {\n      \"max\": 98.6942458152771,\n      \"min\": 98.6942458152771,\n      \"avg\": 98.6942458152771,\n      \"last\": 98.6942458152771,\n      \"last-5-avg\": 98.6942458152771,\n      \"last-10-avg\": 98.6942458152771\n    },\n    \"time_since_restore\": {\n      \"max\": 98.6942458152771,\n      \"min\": 98.6942458152771,\n      \"avg\": 98.6942458152771,\n      \"last\": 98.6942458152771,\n      \"last-5-avg\": 98.6942458152771,\n      \"last-10-avg\": 98.6942458152771\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c054ced3faa70d0b612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c054ced3faa70d0b612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058ac6e86000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058ac6e86000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058ac6e86000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058ac6e86000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058ac6e86000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058ac6e86000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030305f305f62617463685f73697a653d3132382c636c69705f72616e67653d302e323838342c656e745f636f65663d302e303030322c6761655f6c616d6264613d302e393430302c67616d6d613d302e393930382c6c6561726e696e675f726174653d302e303030322c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00015303323556835365,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9907626015214925,\n    \"gae_lambda\": 0.9399688865542699,\n    \"clip_range\": 0.2883921392501237,\n    \"ent_coef\": 0.00017775344944268576,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00015303323556835365,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9907626015214925,\n    \"gae_lambda\": 0.9399688865542699,\n    \"clip_range\": 0.2883921392501237,\n    \"ent_coef\": 0.00017775344944268576,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00015303323556835365,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9907626015214925,\n    \"gae_lambda\": 0.9399688865542699,\n    \"clip_range\": 0.2883921392501237,\n    \"ent_coef\": 0.00017775344944268576\n  },\n  \"experiment_tag\": \"0_batch_size=128,clip_range=0.2884,ent_coef=0.0002,gae_lambda=0.9400,gamma=0.9908,learning_rate=0.0002,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00000_0_batch_size=128,clip_range=0.2884,ent_coef=0.0002,gae_lambda=0.9400,gamma=0.9908,learning_rate=0.0002,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205827.4415581,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -108.23273413359293,\n    \"timestamp\": 1762205939,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00000\",\n    \"date\": \"2025-11-03_15-38-59\",\n    \"time_this_iter_s\": 111.83898329734802,\n    \"time_total_s\": 111.83898329734802,\n    \"pid\": 96058,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00015303323556835365,\n      \"n_steps\": 512,\n      \"batch_size\": 128,\n      \"gamma\": 0.9907626015214925,\n      \"gae_lambda\": 0.9399688865542699,\n      \"clip_range\": 0.2883921392501237,\n      \"ent_coef\": 0.00017775344944268576,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 111.83898329734802,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"0_batch_size=128,clip_range=0.2884,ent_coef=0.0002,gae_lambda=0.9400,gamma=0.9908,learning_rate=0.0002,n_steps=512\"\n  },\n  \"last_result_time\": 1762205939.2839282,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -108.23273413359293,\n      \"min\": -108.23273413359293,\n      \"avg\": -108.23273413359293,\n      \"last\": -108.23273413359293,\n      \"last-5-avg\": -108.23273413359293,\n      \"last-10-avg\": -108.23273413359293\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 111.83898329734802,\n      \"min\": 111.83898329734802,\n      \"avg\": 111.83898329734802,\n      \"last\": 111.83898329734802,\n      \"last-5-avg\": 111.83898329734802,\n      \"last-10-avg\": 111.83898329734802\n    },\n    \"time_total_s\": {\n      \"max\": 111.83898329734802,\n      \"min\": 111.83898329734802,\n      \"avg\": 111.83898329734802,\n      \"last\": 111.83898329734802,\n      \"last-5-avg\": 111.83898329734802,\n      \"last-10-avg\": 111.83898329734802\n    },\n    \"time_since_restore\": {\n      \"max\": 111.83898329734802,\n      \"min\": 111.83898329734802,\n      \"avg\": 111.83898329734802,\n      \"last\": 111.83898329734802,\n      \"last-5-avg\": 111.83898329734802,\n      \"last-10-avg\": 111.83898329734802\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c05b0ee51db51c73612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c05b0ee51db51c73612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405bf5b1e7000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405bf5b1e7000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405bf5b1e7000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405bf5b1e7000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405bf5b1e7000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405bf5b1e7000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00006\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030365f365f62617463685f73697a653d3132382c636c69705f72616e67653d302e313231392c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393835322c67616d6d613d302e393833302c6c6561726e696e675f726174653d302e303030322c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0002125579269459588,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9829798805057919,\n    \"gae_lambda\": 0.9852427960061565,\n    \"clip_range\": 0.12193174919705056,\n    \"ent_coef\": 2.279076747987274e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0002125579269459588,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9829798805057919,\n    \"gae_lambda\": 0.9852427960061565,\n    \"clip_range\": 0.12193174919705056,\n    \"ent_coef\": 2.279076747987274e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0002125579269459588,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9829798805057919,\n    \"gae_lambda\": 0.9852427960061565,\n    \"clip_range\": 0.12193174919705056,\n    \"ent_coef\": 2.279076747987274e-05\n  },\n  \"experiment_tag\": \"6_batch_size=128,clip_range=0.1219,ent_coef=0.0000,gae_lambda=0.9852,gamma=0.9830,learning_rate=0.0002,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00006_6_batch_size=128,clip_range=0.1219,ent_coef=0.0000,gae_lambda=0.9852,gamma=0.9830,learning_rate=0.0002,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205941.014623,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -46.58179138528265,\n    \"timestamp\": 1762206045,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00006\",\n    \"date\": \"2025-11-03_15-40-45\",\n    \"time_this_iter_s\": 104.29576969146729,\n    \"time_total_s\": 104.29576969146729,\n    \"pid\": 96123,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0002125579269459588,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9829798805057919,\n      \"gae_lambda\": 0.9852427960061565,\n      \"clip_range\": 0.12193174919705056,\n      \"ent_coef\": 2.279076747987274e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 104.29576969146729,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_batch_size=128,clip_range=0.1219,ent_coef=0.0000,gae_lambda=0.9852,gamma=0.9830,learning_rate=0.0002,n_steps=1024\"\n  },\n  \"last_result_time\": 1762206045.313171,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -46.58179138528265,\n      \"min\": -46.58179138528265,\n      \"avg\": -46.58179138528265,\n      \"last\": -46.58179138528265,\n      \"last-5-avg\": -46.58179138528265,\n      \"last-10-avg\": -46.58179138528265\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 104.29576969146729,\n      \"min\": 104.29576969146729,\n      \"avg\": 104.29576969146729,\n      \"last\": 104.29576969146729,\n      \"last-5-avg\": 104.29576969146729,\n      \"last-10-avg\": 104.29576969146729\n    },\n    \"time_total_s\": {\n      \"max\": 104.29576969146729,\n      \"min\": 104.29576969146729,\n      \"avg\": 104.29576969146729,\n      \"last\": 104.29576969146729,\n      \"last-5-avg\": 104.29576969146729,\n      \"last-10-avg\": 104.29576969146729\n    },\n    \"time_since_restore\": {\n      \"max\": 104.29576969146729,\n      \"min\": 104.29576969146729,\n      \"avg\": 104.29576969146729,\n      \"last\": 104.29576969146729,\n      \"last-5-avg\": 104.29576969146729,\n      \"last-10-avg\": 104.29576969146729\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c0474a7823de7117612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c0474a7823de7117612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a12ede4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a12ede4000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a12ede4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a12ede4000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a12ede4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a12ede4000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00008\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030385f385f62617463685f73697a653d36342c636c69705f72616e67653d302e313131332c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393135342c67616d6d613d302e393835362c6c6561726e696e675f726174653d302e303030312c6e5f737465705f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00013043495181867907,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"gamma\": 0.9855542767540239,\n    \"gae_lambda\": 0.9153629634566667,\n    \"clip_range\": 0.11132178065510562,\n    \"ent_coef\": 2.5568954189897305e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00013043495181867907,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"gamma\": 0.9855542767540239,\n    \"gae_lambda\": 0.9153629634566667,\n    \"clip_range\": 0.11132178065510562,\n    \"ent_coef\": 2.5568954189897305e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00013043495181867907,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"gamma\": 0.9855542767540239,\n    \"gae_lambda\": 0.9153629634566667,\n    \"clip_range\": 0.11132178065510562,\n    \"ent_coef\": 2.5568954189897305e-05\n  },\n  \"experiment_tag\": \"8_batch_size=64,clip_range=0.1113,ent_coef=0.0000,gae_lambda=0.9154,gamma=0.9856,learning_rate=0.0001,n_steps=2048\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00008_8_batch_size=64,clip_range=0.1113,ent_coef=0.0000,gae_lambda=0.9154,gamma=0.9856,learning_rate=0.0001,n_step_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762206036.00308,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 184.80681415959592,\n    \"timestamp\": 1762206167,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00008\",\n    \"date\": \"2025-11-03_15-42-47\",\n    \"time_this_iter_s\": 131.01532101631165,\n    \"time_total_s\": 131.01532101631165,\n    \"pid\": 96162,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00013043495181867907,\n      \"n_steps\": 2048,\n      \"batch_size\": 64,\n      \"gamma\": 0.9855542767540239,\n      \"gae_lambda\": 0.9153629634566667,\n      \"clip_range\": 0.11132178065510562,\n      \"ent_coef\": 2.5568954189897305e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 131.01532101631165,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_batch_size=64,clip_range=0.1113,ent_coef=0.0000,gae_lambda=0.9154,gamma=0.9856,learning_rate=0.0001,n_steps=2048\"\n  },\n  \"last_result_time\": 1762206167.0211499,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 184.80681415959592,\n      \"min\": 184.80681415959592,\n      \"avg\": 184.80681415959592,\n      \"last\": 184.80681415959592,\n      \"last-5-avg\": 184.80681415959592,\n      \"last-10-avg\": 184.80681415959592\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 131.01532101631165,\n      \"min\": 131.01532101631165,\n      \"avg\": 131.01532101631165,\n      \"last\": 131.01532101631165,\n      \"last-5-avg\": 131.01532101631165,\n      \"last-10-avg\": 131.01532101631165\n    },\n    \"time_total_s\": {\n      \"max\": 131.01532101631165,\n      \"min\": 131.01532101631165,\n      \"avg\": 131.01532101631165,\n      \"last\": 131.01532101631165,\n      \"last-5-avg\": 131.01532101631165,\n      \"last-10-avg\": 131.01532101631165\n    },\n    \"time_since_restore\": {\n      \"max\": 131.01532101631165,\n      \"min\": 131.01532101631165,\n      \"avg\": 131.01532101631165,\n      \"last\": 131.01532101631165,\n      \"last-5-avg\": 131.01532101631165,\n      \"last-10-avg\": 131.01532101631165\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406719d16bedad41612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406719d16bedad41612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060607d82800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060607d82800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060607d82800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060607d82800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060607d82800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060607d82800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00001\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030315f315f62617463685f73697a653d3235362c636c69705f72616e67653d302e313237332c656e745f636f65663d302e303030342c6761655f6c616d6264613d302e393131372c67616d6d613d302e393835382c6c6561726e696e675f726174653d302e303030322c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00019614137701561363,\n    \"n_steps\": 2048,\n    \"batch_size\": 256,\n    \"gamma\": 0.985809480255559,\n    \"gae_lambda\": 0.911692055247831,\n    \"clip_range\": 0.12734112709428977,\n    \"ent_coef\": 0.0004199500585636921,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00019614137701561363,\n    \"n_steps\": 2048,\n    \"batch_size\": 256,\n    \"gamma\": 0.985809480255559,\n    \"gae_lambda\": 0.911692055247831,\n    \"clip_range\": 0.12734112709428977,\n    \"ent_coef\": 0.0004199500585636921,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00019614137701561363,\n    \"n_steps\": 2048,\n    \"batch_size\": 256,\n    \"gamma\": 0.985809480255559,\n    \"gae_lambda\": 0.911692055247831,\n    \"clip_range\": 0.12734112709428977,\n    \"ent_coef\": 0.0004199500585636921\n  },\n  \"experiment_tag\": \"1_batch_size=256,clip_range=0.1273,ent_coef=0.0004,gae_lambda=0.9117,gamma=0.9858,learning_rate=0.0002,n_steps=2048\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00001_1_batch_size=256,clip_range=0.1273,ent_coef=0.0004,gae_lambda=0.9117,gamma=0.9858,learning_rate=0.0002,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205827.4453728,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -57.8797515411085,\n    \"timestamp\": 1762205928,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00001\",\n    \"date\": \"2025-11-03_15-38-48\",\n    \"time_this_iter_s\": 100.9756760597229,\n    \"time_total_s\": 100.9756760597229,\n    \"pid\": 96056,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00019614137701561363,\n      \"n_steps\": 2048,\n      \"batch_size\": 256,\n      \"gamma\": 0.985809480255559,\n      \"gae_lambda\": 0.911692055247831,\n      \"clip_range\": 0.12734112709428977,\n      \"ent_coef\": 0.0004199500585636921,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 100.9756760597229,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_batch_size=256,clip_range=0.1273,ent_coef=0.0004,gae_lambda=0.9117,gamma=0.9858,learning_rate=0.0002,n_steps=2048\"\n  },\n  \"last_result_time\": 1762205928.424072,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -57.8797515411085,\n      \"min\": -57.8797515411085,\n      \"avg\": -57.8797515411085,\n      \"last\": -57.8797515411085,\n      \"last-5-avg\": -57.8797515411085,\n      \"last-10-avg\": -57.8797515411085\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 100.9756760597229,\n      \"min\": 100.9756760597229,\n      \"avg\": 100.9756760597229,\n      \"last\": 100.9756760597229,\n      \"last-5-avg\": 100.9756760597229,\n      \"last-10-avg\": 100.9756760597229\n    },\n    \"time_total_s\": {\n      \"max\": 100.9756760597229,\n      \"min\": 100.9756760597229,\n      \"avg\": 100.9756760597229,\n      \"last\": 100.9756760597229,\n      \"last-5-avg\": 100.9756760597229,\n      \"last-10-avg\": 100.9756760597229\n    },\n    \"time_since_restore\": {\n      \"max\": 100.9756760597229,\n      \"min\": 100.9756760597229,\n      \"avg\": 100.9756760597229,\n      \"last\": 100.9756760597229,\n      \"last-5-avg\": 100.9756760597229,\n      \"last-10-avg\": 100.9756760597229\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c04cf09bb2d0d553612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c04cf09bb2d0d553612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740593e717a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740593e717a000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740593e717a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740593e717a000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740593e717a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740593e717a000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00011\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303031315f31315f62617463685f73697a653d3132382c636c69705f72616e67653d302e323435302c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393538332c67616d6d613d302e393932312c6c6561726e696e675f726174653d302e303030302c6e5f73745f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 4.123345422615027e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9921356825998202,\n    \"gae_lambda\": 0.9582987246361087,\n    \"clip_range\": 0.24495933859300753,\n    \"ent_coef\": 1.67526609565421e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 4.123345422615027e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9921356825998202,\n    \"gae_lambda\": 0.9582987246361087,\n    \"clip_range\": 0.24495933859300753,\n    \"ent_coef\": 1.67526609565421e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 4.123345422615027e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9921356825998202,\n    \"gae_lambda\": 0.9582987246361087,\n    \"clip_range\": 0.24495933859300753,\n    \"ent_coef\": 1.67526609565421e-05\n  },\n  \"experiment_tag\": \"11_batch_size=128,clip_range=0.2450,ent_coef=0.0000,gae_lambda=0.9583,gamma=0.9921,learning_rate=0.0000,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00011_11_batch_size=128,clip_range=0.2450,ent_coef=0.0000,gae_lambda=0.9583,gamma=0.9921,learning_rate=0.0000,n_st_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762206076.0386748,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -43.388292074292636,\n    \"timestamp\": 1762206178,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00011\",\n    \"date\": \"2025-11-03_15-42-58\",\n    \"time_this_iter_s\": 102.37149286270142,\n    \"time_total_s\": 102.37149286270142,\n    \"pid\": 96189,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 4.123345422615027e-05,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9921356825998202,\n      \"gae_lambda\": 0.9582987246361087,\n      \"clip_range\": 0.24495933859300753,\n      \"ent_coef\": 1.67526609565421e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 102.37149286270142,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11_batch_size=128,clip_range=0.2450,ent_coef=0.0000,gae_lambda=0.9583,gamma=0.9921,learning_rate=0.0000,n_steps=1024\"\n  },\n  \"last_result_time\": 1762206178.4131498,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -43.388292074292636,\n      \"min\": -43.388292074292636,\n      \"avg\": -43.388292074292636,\n      \"last\": -43.388292074292636,\n      \"last-5-avg\": -43.388292074292636,\n      \"last-10-avg\": -43.388292074292636\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 102.37149286270142,\n      \"min\": 102.37149286270142,\n      \"avg\": 102.37149286270142,\n      \"last\": 102.37149286270142,\n      \"last-5-avg\": 102.37149286270142,\n      \"last-10-avg\": 102.37149286270142\n    },\n    \"time_total_s\": {\n      \"max\": 102.37149286270142,\n      \"min\": 102.37149286270142,\n      \"avg\": 102.37149286270142,\n      \"last\": 102.37149286270142,\n      \"last-5-avg\": 102.37149286270142,\n      \"last-10-avg\": 102.37149286270142\n    },\n    \"time_since_restore\": {\n      \"max\": 102.37149286270142,\n      \"min\": 102.37149286270142,\n      \"avg\": 102.37149286270142,\n      \"last\": 102.37149286270142,\n      \"last-5-avg\": 102.37149286270142,\n      \"last-10-avg\": 102.37149286270142\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c045b1b38e003102612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c045b1b38e003102612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405997c68a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405997c68a000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405997c68a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405997c68a000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405997c68a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405997c68a000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00005\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030355f355f62617463685f73697a653d3132382c636c69705f72616e67653d302e323438372c656e745f636f65663d302e303030312c6761655f6c616d6264613d302e393334372c67616d6d613d302e393930302c6c6561726e696e675f726174653d302e303030342c6e5f7374655f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0004259464491911062,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9899577663513816,\n    \"gae_lambda\": 0.9347189012620818,\n    \"clip_range\": 0.24868540852092177,\n    \"ent_coef\": 8.280008550982645e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0004259464491911062,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9899577663513816,\n    \"gae_lambda\": 0.9347189012620818,\n    \"clip_range\": 0.24868540852092177,\n    \"ent_coef\": 8.280008550982645e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0004259464491911062,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9899577663513816,\n    \"gae_lambda\": 0.9347189012620818,\n    \"clip_range\": 0.24868540852092177,\n    \"ent_coef\": 8.280008550982645e-05\n  },\n  \"experiment_tag\": \"5_batch_size=128,clip_range=0.2487,ent_coef=0.0001,gae_lambda=0.9347,gamma=0.9900,learning_rate=0.0004,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00005_5_batch_size=128,clip_range=0.2487,ent_coef=0.0001,gae_lambda=0.9347,gamma=0.9900,learning_rate=0.0004,n_ste_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205930.901835,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -113.2533783792217,\n    \"timestamp\": 1762206035,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00005\",\n    \"date\": \"2025-11-03_15-40-35\",\n    \"time_this_iter_s\": 104.66103506088257,\n    \"time_total_s\": 104.66103506088257,\n    \"pid\": 96119,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0004259464491911062,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9899577663513816,\n      \"gae_lambda\": 0.9347189012620818,\n      \"clip_range\": 0.24868540852092177,\n      \"ent_coef\": 8.280008550982645e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 104.66103506088257,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_batch_size=128,clip_range=0.2487,ent_coef=0.0001,gae_lambda=0.9347,gamma=0.9900,learning_rate=0.0004,n_steps=1024\"\n  },\n  \"last_result_time\": 1762206035.565372,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -113.2533783792217,\n      \"min\": -113.2533783792217,\n      \"avg\": -113.2533783792217,\n      \"last\": -113.2533783792217,\n      \"last-5-avg\": -113.2533783792217,\n      \"last-10-avg\": -113.2533783792217\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 104.66103506088257,\n      \"min\": 104.66103506088257,\n      \"avg\": 104.66103506088257,\n      \"last\": 104.66103506088257,\n      \"last-5-avg\": 104.66103506088257,\n      \"last-10-avg\": 104.66103506088257\n    },\n    \"time_total_s\": {\n      \"max\": 104.66103506088257,\n      \"min\": 104.66103506088257,\n      \"avg\": 104.66103506088257,\n      \"last\": 104.66103506088257,\n      \"last-5-avg\": 104.66103506088257,\n      \"last-10-avg\": 104.66103506088257\n    },\n    \"time_since_restore\": {\n      \"max\": 104.66103506088257,\n      \"min\": 104.66103506088257,\n      \"avg\": 104.66103506088257,\n      \"last\": 104.66103506088257,\n      \"last-5-avg\": 104.66103506088257,\n      \"last-10-avg\": 104.66103506088257\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c05c503759f31153612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c05c503759f31153612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a2a4e66000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a2a4e66000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a2a4e66000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a2a4e66000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405a2a4e66000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405a2a4e66000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00010\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303031305f31305f62617463685f73697a653d3132382c636c69705f72616e67653d302e323935332c656e745f636f65663d302e303030312c6761655f6c616d6264613d302e393230352c67616d6d613d302e393832332c6c6561726e696e675f726174653d302e303030312c6e5f73745f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 7.042772913261893e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9822564185415535,\n    \"gae_lambda\": 0.9205465638446534,\n    \"clip_range\": 0.2953318027984856,\n    \"ent_coef\": 7.008291797449938e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 7.042772913261893e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9822564185415535,\n    \"gae_lambda\": 0.9205465638446534,\n    \"clip_range\": 0.2953318027984856,\n    \"ent_coef\": 7.008291797449938e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 7.042772913261893e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 128,\n    \"gamma\": 0.9822564185415535,\n    \"gae_lambda\": 0.9205465638446534,\n    \"clip_range\": 0.2953318027984856,\n    \"ent_coef\": 7.008291797449938e-05\n  },\n  \"experiment_tag\": \"10_batch_size=128,clip_range=0.2953,ent_coef=0.0001,gae_lambda=0.9205,gamma=0.9823,learning_rate=0.0001,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00010_10_batch_size=128,clip_range=0.2953,ent_coef=0.0001,gae_lambda=0.9205,gamma=0.9823,learning_rate=0.0001,n_st_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762206046.990965,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -108.51470048595452,\n    \"timestamp\": 1762206153,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00010\",\n    \"date\": \"2025-11-03_15-42-33\",\n    \"time_this_iter_s\": 106.76260614395142,\n    \"time_total_s\": 106.76260614395142,\n    \"pid\": 96171,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 7.042772913261893e-05,\n      \"n_steps\": 512,\n      \"batch_size\": 128,\n      \"gamma\": 0.9822564185415535,\n      \"gae_lambda\": 0.9205465638446534,\n      \"clip_range\": 0.2953318027984856,\n      \"ent_coef\": 7.008291797449938e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 106.76260614395142,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_batch_size=128,clip_range=0.2953,ent_coef=0.0001,gae_lambda=0.9205,gamma=0.9823,learning_rate=0.0001,n_steps=512\"\n  },\n  \"last_result_time\": 1762206153.756147,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -108.51470048595452,\n      \"min\": -108.51470048595452,\n      \"avg\": -108.51470048595452,\n      \"last\": -108.51470048595452,\n      \"last-5-avg\": -108.51470048595452,\n      \"last-10-avg\": -108.51470048595452\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 106.76260614395142,\n      \"min\": 106.76260614395142,\n      \"avg\": 106.76260614395142,\n      \"last\": 106.76260614395142,\n      \"last-5-avg\": 106.76260614395142,\n      \"last-10-avg\": 106.76260614395142\n    },\n    \"time_total_s\": {\n      \"max\": 106.76260614395142,\n      \"min\": 106.76260614395142,\n      \"avg\": 106.76260614395142,\n      \"last\": 106.76260614395142,\n      \"last-5-avg\": 106.76260614395142,\n      \"last-10-avg\": 106.76260614395142\n    },\n    \"time_since_restore\": {\n      \"max\": 106.76260614395142,\n      \"min\": 106.76260614395142,\n      \"avg\": 106.76260614395142,\n      \"last\": 106.76260614395142,\n      \"last-5-avg\": 106.76260614395142,\n      \"last-10-avg\": 106.76260614395142\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c05b20f0da4e9a3d612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c05b20f0da4e9a3d612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ab0ce8a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ab0ce8a000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ab0ce8a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ab0ce8a000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ab0ce8a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ab0ce8a000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"3e4e6_00003\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d33372d3036948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f33653465365f30303030335f335f62617463685f73697a653d36342c636c69705f72616e67653d302e323632302c656e745f636f65663d302e303030312c6761655f6c616d6264613d302e393635332c67616d6d613d302e393935332c6c6561726e696e675f726174653d302e303030372c6e5f737465705f323032352d31312d30335f31352d33372d3036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d33372d30369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0006913588178012045,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"gamma\": 0.99528055168809,\n    \"gae_lambda\": 0.9653322457825322,\n    \"clip_range\": 0.2619739067402881,\n    \"ent_coef\": 0.00011332992030124485,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0006913588178012045,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"gamma\": 0.99528055168809,\n    \"gae_lambda\": 0.9653322457825322,\n    \"clip_range\": 0.2619739067402881,\n    \"ent_coef\": 0.00011332992030124485,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0006913588178012045,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"gamma\": 0.99528055168809,\n    \"gae_lambda\": 0.9653322457825322,\n    \"clip_range\": 0.2619739067402881,\n    \"ent_coef\": 0.00011332992030124485\n  },\n  \"experiment_tag\": \"3_batch_size=64,clip_range=0.2620,ent_coef=0.0001,gae_lambda=0.9653,gamma=0.9953,learning_rate=0.0007,n_steps=2048\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_3e4e6_00003_3_batch_size=64,clip_range=0.2620,ent_coef=0.0001,gae_lambda=0.9653,gamma=0.9953,learning_rate=0.0007,n_step_2025-11-03_15-37-06\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205827.4697468,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": -87.63722478795202,\n    \"timestamp\": 1762205964,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3e4e6_00003\",\n    \"date\": \"2025-11-03_15-39-24\",\n    \"time_this_iter_s\": 137.18918180465698,\n    \"time_total_s\": 137.18918180465698,\n    \"pid\": 96057,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0006913588178012045,\n      \"n_steps\": 2048,\n      \"batch_size\": 64,\n      \"gamma\": 0.99528055168809,\n      \"gae_lambda\": 0.9653322457825322,\n      \"clip_range\": 0.2619739067402881,\n      \"ent_coef\": 0.00011332992030124485,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 137.18918180465698,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_batch_size=64,clip_range=0.2620,ent_coef=0.0001,gae_lambda=0.9653,gamma=0.9953,learning_rate=0.0007,n_steps=2048\"\n  },\n  \"last_result_time\": 1762205964.6616268,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": -87.63722478795202,\n      \"min\": -87.63722478795202,\n      \"avg\": -87.63722478795202,\n      \"last\": -87.63722478795202,\n      \"last-5-avg\": -87.63722478795202,\n      \"last-10-avg\": -87.63722478795202\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 137.18918180465698,\n      \"min\": 137.18918180465698,\n      \"avg\": 137.18918180465698,\n      \"last\": 137.18918180465698,\n      \"last-5-avg\": 137.18918180465698,\n      \"last-10-avg\": 137.18918180465698\n    },\n    \"time_total_s\": {\n      \"max\": 137.18918180465698,\n      \"min\": 137.18918180465698,\n      \"avg\": 137.18918180465698,\n      \"last\": 137.18918180465698,\n      \"last-5-avg\": 137.18918180465698,\n      \"last-10-avg\": 137.18918180465698\n    },\n    \"time_since_restore\": {\n      \"max\": 137.18918180465698,\n      \"min\": 137.18918180465698,\n      \"avg\": 137.18918180465698,\n      \"last\": 137.18918180465698,\n      \"last-5-avg\": 137.18918180465698,\n      \"last-10-avg\": 137.18918180465698\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447c055e8c84a7a1d16612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447c055e8c84a7a1d16612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474061260dc7000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474061260dc7000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474061260dc7000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474061260dc7000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474061260dc7000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474061260dc7000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 391929.770465291, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": "mean_reward", "_total_time": 2637.181251525879, "_iteration": 3420, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1762205826.010598, "_session_str": "2025-11-03_15-37-06", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1762205826.010598}}