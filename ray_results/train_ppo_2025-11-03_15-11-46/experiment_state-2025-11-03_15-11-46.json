{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00011\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303031315f31315f62617463685f73697a653d33322c636c69705f72616e67653d302e323538312c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393536322c67616d6d613d302e393839352c6c6561726e696e675f726174653d302e303030302c6e5f7374655f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 3.6946657209008726e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 32,\n    \"gamma\": 0.9895064676200421,\n    \"gae_lambda\": 0.9561976154889212,\n    \"clip_range\": 0.2580832771015101,\n    \"ent_coef\": 3.1113663674059e-05,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 3.6946657209008726e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 32,\n    \"gamma\": 0.9895064676200421,\n    \"gae_lambda\": 0.9561976154889212,\n    \"clip_range\": 0.2580832771015101,\n    \"ent_coef\": 3.1113663674059e-05,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 3.6946657209008726e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 32,\n    \"gamma\": 0.9895064676200421,\n    \"gae_lambda\": 0.9561976154889212,\n    \"clip_range\": 0.2580832771015101,\n    \"ent_coef\": 3.1113663674059e-05\n  },\n  \"experiment_tag\": \"11_batch_size=32,clip_range=0.2581,ent_coef=0.0000,gae_lambda=0.9562,gamma=0.9895,learning_rate=0.0000,n_steps=128\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00011_11_batch_size=32,clip_range=0.2581,ent_coef=0.0000,gae_lambda=0.9562,gamma=0.9895,learning_rate=0.0000,n_ste_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204382.574207,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 416.0,\n    \"timestamp\": 1762204413,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00011\",\n    \"date\": \"2025-11-03_15-13-33\",\n    \"time_this_iter_s\": 30.972954273223877,\n    \"time_total_s\": 30.972954273223877,\n    \"pid\": 94783,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 3.6946657209008726e-05,\n      \"n_steps\": 128,\n      \"batch_size\": 32,\n      \"gamma\": 0.9895064676200421,\n      \"gae_lambda\": 0.9561976154889212,\n      \"clip_range\": 0.2580832771015101,\n      \"ent_coef\": 3.1113663674059e-05,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 30.972954273223877,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11_batch_size=32,clip_range=0.2581,ent_coef=0.0000,gae_lambda=0.9562,gamma=0.9895,learning_rate=0.0000,n_steps=128\"\n  },\n  \"last_result_time\": 1762204413.549404,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 416.0,\n      \"min\": 416.0,\n      \"avg\": 416.0,\n      \"last\": 416.0,\n      \"last-5-avg\": 416.0,\n      \"last-10-avg\": 416.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 30.972954273223877,\n      \"min\": 30.972954273223877,\n      \"avg\": 30.972954273223877,\n      \"last\": 30.972954273223877,\n      \"last-5-avg\": 30.972954273223877,\n      \"last-10-avg\": 30.972954273223877\n    },\n    \"time_total_s\": {\n      \"max\": 30.972954273223877,\n      \"min\": 30.972954273223877,\n      \"avg\": 30.972954273223877,\n      \"last\": 30.972954273223877,\n      \"last-5-avg\": 30.972954273223877,\n      \"last-10-avg\": 30.972954273223877\n    },\n    \"time_since_restore\": {\n      \"max\": 30.972954273223877,\n      \"min\": 30.972954273223877,\n      \"avg\": 30.972954273223877,\n      \"last\": 30.972954273223877,\n      \"last-5-avg\": 30.972954273223877,\n      \"last-10-avg\": 30.972954273223877\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407a000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407a000000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ef91388000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ef91388000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ef91388000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ef91388000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ef91388000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ef91388000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00008\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030385f385f62617463685f73697a653d3132382c636c69705f72616e67653d302e313137392c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393538372c67616d6d613d302e393630322c6c6561726e696e675f726174653d302e303030322c6e5f7374655f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0002416643719154849,\n    \"n_steps\": 128,\n    \"batch_size\": 128,\n    \"gamma\": 0.9602234907457016,\n    \"gae_lambda\": 0.9586873881358192,\n    \"clip_range\": 0.11786114620809694,\n    \"ent_coef\": 1.755842726303451e-06,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0002416643719154849,\n    \"n_steps\": 128,\n    \"batch_size\": 128,\n    \"gamma\": 0.9602234907457016,\n    \"gae_lambda\": 0.9586873881358192,\n    \"clip_range\": 0.11786114620809694,\n    \"ent_coef\": 1.755842726303451e-06,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0002416643719154849,\n    \"n_steps\": 128,\n    \"batch_size\": 128,\n    \"gamma\": 0.9602234907457016,\n    \"gae_lambda\": 0.9586873881358192,\n    \"clip_range\": 0.11786114620809694,\n    \"ent_coef\": 1.755842726303451e-06\n  },\n  \"experiment_tag\": \"8_batch_size=128,clip_range=0.1179,ent_coef=0.0000,gae_lambda=0.9587,gamma=0.9602,learning_rate=0.0002,n_steps=128\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00008_8_batch_size=128,clip_range=0.1179,ent_coef=0.0000,gae_lambda=0.9587,gamma=0.9602,learning_rate=0.0002,n_ste_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204366.5481138,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204386,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00008\",\n    \"date\": \"2025-11-03_15-13-06\",\n    \"time_this_iter_s\": 19.742126941680908,\n    \"time_total_s\": 19.742126941680908,\n    \"pid\": 94768,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0002416643719154849,\n      \"n_steps\": 128,\n      \"batch_size\": 128,\n      \"gamma\": 0.9602234907457016,\n      \"gae_lambda\": 0.9586873881358192,\n      \"clip_range\": 0.11786114620809694,\n      \"ent_coef\": 1.755842726303451e-06,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 19.742126941680908,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_batch_size=128,clip_range=0.1179,ent_coef=0.0000,gae_lambda=0.9587,gamma=0.9602,learning_rate=0.0002,n_steps=128\"\n  },\n  \"last_result_time\": 1762204386.2929862,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 19.742126941680908,\n      \"min\": 19.742126941680908,\n      \"avg\": 19.742126941680908,\n      \"last\": 19.742126941680908,\n      \"last-5-avg\": 19.742126941680908,\n      \"last-10-avg\": 19.742126941680908\n    },\n    \"time_total_s\": {\n      \"max\": 19.742126941680908,\n      \"min\": 19.742126941680908,\n      \"avg\": 19.742126941680908,\n      \"last\": 19.742126941680908,\n      \"last-5-avg\": 19.742126941680908,\n      \"last-10-avg\": 19.742126941680908\n    },\n    \"time_since_restore\": {\n      \"max\": 19.742126941680908,\n      \"min\": 19.742126941680908,\n      \"avg\": 19.742126941680908,\n      \"last\": 19.742126941680908,\n      \"last-5-avg\": 19.742126941680908,\n      \"last-10-avg\": 19.742126941680908\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474033bdfc08000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474033bdfc08000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474033bdfc08000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474033bdfc08000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474033bdfc08000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474033bdfc08000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00001\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030315f315f62617463685f73697a653d33322c636c69705f72616e67653d302e313031302c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393037382c67616d6d613d302e393937392c6c6561726e696e675f726174653d302e303030302c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 3.396916825258222e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 32,\n    \"gamma\": 0.9979431742563525,\n    \"gae_lambda\": 0.9078360547638485,\n    \"clip_range\": 0.10098592719353383,\n    \"ent_coef\": 5.629652075334217e-06,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 3.396916825258222e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 32,\n    \"gamma\": 0.9979431742563525,\n    \"gae_lambda\": 0.9078360547638485,\n    \"clip_range\": 0.10098592719353383,\n    \"ent_coef\": 5.629652075334217e-06,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 3.396916825258222e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 32,\n    \"gamma\": 0.9979431742563525,\n    \"gae_lambda\": 0.9078360547638485,\n    \"clip_range\": 0.10098592719353383,\n    \"ent_coef\": 5.629652075334217e-06\n  },\n  \"experiment_tag\": \"1_batch_size=32,clip_range=0.1010,ent_coef=0.0000,gae_lambda=0.9078,gamma=0.9979,learning_rate=0.0000,n_steps=128\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00001_1_batch_size=32,clip_range=0.1010,ent_coef=0.0000,gae_lambda=0.9078,gamma=0.9979,learning_rate=0.0000,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204308.248369,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204343,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00001\",\n    \"date\": \"2025-11-03_15-12-23\",\n    \"time_this_iter_s\": 34.98759078979492,\n    \"time_total_s\": 34.98759078979492,\n    \"pid\": 94731,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 3.396916825258222e-05,\n      \"n_steps\": 128,\n      \"batch_size\": 32,\n      \"gamma\": 0.9979431742563525,\n      \"gae_lambda\": 0.9078360547638485,\n      \"clip_range\": 0.10098592719353383,\n      \"ent_coef\": 5.629652075334217e-06,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 34.98759078979492,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_batch_size=32,clip_range=0.1010,ent_coef=0.0000,gae_lambda=0.9078,gamma=0.9979,learning_rate=0.0000,n_steps=128\"\n  },\n  \"last_result_time\": 1762204343.2390778,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.98759078979492,\n      \"min\": 34.98759078979492,\n      \"avg\": 34.98759078979492,\n      \"last\": 34.98759078979492,\n      \"last-5-avg\": 34.98759078979492,\n      \"last-10-avg\": 34.98759078979492\n    },\n    \"time_total_s\": {\n      \"max\": 34.98759078979492,\n      \"min\": 34.98759078979492,\n      \"avg\": 34.98759078979492,\n      \"last\": 34.98759078979492,\n      \"last-5-avg\": 34.98759078979492,\n      \"last-10-avg\": 34.98759078979492\n    },\n    \"time_since_restore\": {\n      \"max\": 34.98759078979492,\n      \"min\": 34.98759078979492,\n      \"avg\": 34.98759078979492,\n      \"last\": 34.98759078979492,\n      \"last-5-avg\": 34.98759078979492,\n      \"last-10-avg\": 34.98759078979492\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740417e6960000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740417e6960000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740417e6960000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740417e6960000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740417e6960000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740417e6960000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00006\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030365f365f62617463685f73697a653d33322c636c69705f72616e67653d302e313130342c656e745f636f65663d302e303030322c6761655f6c616d6264613d302e393835362c67616d6d613d302e393733322c6c6561726e696e675f726174653d302e303030352c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0004880648850322819,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9732371394069552,\n    \"gae_lambda\": 0.9855514987704039,\n    \"clip_range\": 0.11040062018371195,\n    \"ent_coef\": 0.00020718092384407408,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0004880648850322819,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9732371394069552,\n    \"gae_lambda\": 0.9855514987704039,\n    \"clip_range\": 0.11040062018371195,\n    \"ent_coef\": 0.00020718092384407408,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0004880648850322819,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9732371394069552,\n    \"gae_lambda\": 0.9855514987704039,\n    \"clip_range\": 0.11040062018371195,\n    \"ent_coef\": 0.00020718092384407408\n  },\n  \"experiment_tag\": \"6_batch_size=32,clip_range=0.1104,ent_coef=0.0002,gae_lambda=0.9856,gamma=0.9732,learning_rate=0.0005,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00006_6_batch_size=32,clip_range=0.1104,ent_coef=0.0002,gae_lambda=0.9856,gamma=0.9732,learning_rate=0.0005,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204335.537899,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204370,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00006\",\n    \"date\": \"2025-11-03_15-12-50\",\n    \"time_this_iter_s\": 34.59688186645508,\n    \"time_total_s\": 34.59688186645508,\n    \"pid\": 94751,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0004880648850322819,\n      \"n_steps\": 256,\n      \"batch_size\": 32,\n      \"gamma\": 0.9732371394069552,\n      \"gae_lambda\": 0.9855514987704039,\n      \"clip_range\": 0.11040062018371195,\n      \"ent_coef\": 0.00020718092384407408,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 34.59688186645508,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_batch_size=32,clip_range=0.1104,ent_coef=0.0002,gae_lambda=0.9856,gamma=0.9732,learning_rate=0.0005,n_steps=256\"\n  },\n  \"last_result_time\": 1762204370.13731,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.59688186645508,\n      \"min\": 34.59688186645508,\n      \"avg\": 34.59688186645508,\n      \"last\": 34.59688186645508,\n      \"last-5-avg\": 34.59688186645508,\n      \"last-10-avg\": 34.59688186645508\n    },\n    \"time_total_s\": {\n      \"max\": 34.59688186645508,\n      \"min\": 34.59688186645508,\n      \"avg\": 34.59688186645508,\n      \"last\": 34.59688186645508,\n      \"last-5-avg\": 34.59688186645508,\n      \"last-10-avg\": 34.59688186645508\n    },\n    \"time_since_restore\": {\n      \"max\": 34.59688186645508,\n      \"min\": 34.59688186645508,\n      \"avg\": 34.59688186645508,\n      \"last\": 34.59688186645508,\n      \"last-5-avg\": 34.59688186645508,\n      \"last-10-avg\": 34.59688186645508\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740414c66a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740414c66a0000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740414c66a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740414c66a0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740414c66a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740414c66a0000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00005\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030355f355f62617463685f73697a653d33322c636c69705f72616e67653d302e323733322c656e745f636f65663d302e303032362c6761655f6c616d6264613d302e393537332c67616d6d613d302e393839392c6c6561726e696e675f726174653d302e303030312c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00012480190285189333,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9899439646186576,\n    \"gae_lambda\": 0.9573137228061107,\n    \"clip_range\": 0.27324235070667996,\n    \"ent_coef\": 0.002605688576766252,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00012480190285189333,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9899439646186576,\n    \"gae_lambda\": 0.9573137228061107,\n    \"clip_range\": 0.27324235070667996,\n    \"ent_coef\": 0.002605688576766252,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00012480190285189333,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9899439646186576,\n    \"gae_lambda\": 0.9573137228061107,\n    \"clip_range\": 0.27324235070667996,\n    \"ent_coef\": 0.002605688576766252\n  },\n  \"experiment_tag\": \"5_batch_size=32,clip_range=0.2732,ent_coef=0.0026,gae_lambda=0.9573,gamma=0.9899,learning_rate=0.0001,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00005_5_batch_size=32,clip_range=0.2732,ent_coef=0.0026,gae_lambda=0.9573,gamma=0.9899,learning_rate=0.0001,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204335.474912,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204368,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00005\",\n    \"date\": \"2025-11-03_15-12-48\",\n    \"time_this_iter_s\": 33.26939392089844,\n    \"time_total_s\": 33.26939392089844,\n    \"pid\": 94750,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00012480190285189333,\n      \"n_steps\": 256,\n      \"batch_size\": 32,\n      \"gamma\": 0.9899439646186576,\n      \"gae_lambda\": 0.9573137228061107,\n      \"clip_range\": 0.27324235070667996,\n      \"ent_coef\": 0.002605688576766252,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 33.26939392089844,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_batch_size=32,clip_range=0.2732,ent_coef=0.0026,gae_lambda=0.9573,gamma=0.9899,learning_rate=0.0001,n_steps=256\"\n  },\n  \"last_result_time\": 1762204368.746992,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.26939392089844,\n      \"min\": 33.26939392089844,\n      \"avg\": 33.26939392089844,\n      \"last\": 33.26939392089844,\n      \"last-5-avg\": 33.26939392089844,\n      \"last-10-avg\": 33.26939392089844\n    },\n    \"time_total_s\": {\n      \"max\": 33.26939392089844,\n      \"min\": 33.26939392089844,\n      \"avg\": 33.26939392089844,\n      \"last\": 33.26939392089844,\n      \"last-5-avg\": 33.26939392089844,\n      \"last-10-avg\": 33.26939392089844\n    },\n    \"time_since_restore\": {\n      \"max\": 33.26939392089844,\n      \"min\": 33.26939392089844,\n      \"avg\": 33.26939392089844,\n      \"last\": 33.26939392089844,\n      \"last-5-avg\": 33.26939392089844,\n      \"last-10-avg\": 33.26939392089844\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040a27b80000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040a27b80000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040a27b80000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040a27b80000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040a27b80000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040a27b80000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00004\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030345f345f62617463685f73697a653d33322c636c69705f72616e67653d302e323634342c656e745f636f65663d302e303030342c6761655f6c616d6264613d302e393635332c67616d6d613d302e393539372c6c6561726e696e675f726174653d302e303030322c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00019801766774190678,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9597209411443507,\n    \"gae_lambda\": 0.9653402606526792,\n    \"clip_range\": 0.26441169266842834,\n    \"ent_coef\": 0.0004164155994879522,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00019801766774190678,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9597209411443507,\n    \"gae_lambda\": 0.9653402606526792,\n    \"clip_range\": 0.26441169266842834,\n    \"ent_coef\": 0.0004164155994879522,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00019801766774190678,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9597209411443507,\n    \"gae_lambda\": 0.9653402606526792,\n    \"clip_range\": 0.26441169266842834,\n    \"ent_coef\": 0.0004164155994879522\n  },\n  \"experiment_tag\": \"4_batch_size=32,clip_range=0.2644,ent_coef=0.0004,gae_lambda=0.9653,gamma=0.9597,learning_rate=0.0002,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00004_4_batch_size=32,clip_range=0.2644,ent_coef=0.0004,gae_lambda=0.9653,gamma=0.9597,learning_rate=0.0002,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204329.535189,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204364,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00004\",\n    \"date\": \"2025-11-03_15-12-44\",\n    \"time_this_iter_s\": 34.757019996643066,\n    \"time_total_s\": 34.757019996643066,\n    \"pid\": 94743,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00019801766774190678,\n      \"n_steps\": 256,\n      \"batch_size\": 32,\n      \"gamma\": 0.9597209411443507,\n      \"gae_lambda\": 0.9653402606526792,\n      \"clip_range\": 0.26441169266842834,\n      \"ent_coef\": 0.0004164155994879522,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 34.757019996643066,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_batch_size=32,clip_range=0.2644,ent_coef=0.0004,gae_lambda=0.9653,gamma=0.9597,learning_rate=0.0002,n_steps=256\"\n  },\n  \"last_result_time\": 1762204364.2947462,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.757019996643066,\n      \"min\": 34.757019996643066,\n      \"avg\": 34.757019996643066,\n      \"last\": 34.757019996643066,\n      \"last-5-avg\": 34.757019996643066,\n      \"last-10-avg\": 34.757019996643066\n    },\n    \"time_total_s\": {\n      \"max\": 34.757019996643066,\n      \"min\": 34.757019996643066,\n      \"avg\": 34.757019996643066,\n      \"last\": 34.757019996643066,\n      \"last-5-avg\": 34.757019996643066,\n      \"last-10-avg\": 34.757019996643066\n    },\n    \"time_since_restore\": {\n      \"max\": 34.757019996643066,\n      \"min\": 34.757019996643066,\n      \"avg\": 34.757019996643066,\n      \"last\": 34.757019996643066,\n      \"last-5-avg\": 34.757019996643066,\n      \"last-10-avg\": 34.757019996643066\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404160e608000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404160e608000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404160e608000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404160e608000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404160e608000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404160e608000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00003\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030335f335f62617463685f73697a653d36342c636c69705f72616e67653d302e313039352c656e745f636f65663d302e303033362c6761655f6c616d6264613d302e393639332c67616d6d613d302e393838342c6c6561726e696e675f726174653d302e303030312c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00012485682348698199,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9884010882947512,\n    \"gae_lambda\": 0.9693100526763685,\n    \"clip_range\": 0.10953605650972704,\n    \"ent_coef\": 0.0035585686132270705,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00012485682348698199,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9884010882947512,\n    \"gae_lambda\": 0.9693100526763685,\n    \"clip_range\": 0.10953605650972704,\n    \"ent_coef\": 0.0035585686132270705,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00012485682348698199,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9884010882947512,\n    \"gae_lambda\": 0.9693100526763685,\n    \"clip_range\": 0.10953605650972704,\n    \"ent_coef\": 0.0035585686132270705\n  },\n  \"experiment_tag\": \"3_batch_size=64,clip_range=0.1095,ent_coef=0.0036,gae_lambda=0.9693,gamma=0.9884,learning_rate=0.0001,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00003_3_batch_size=64,clip_range=0.1095,ent_coef=0.0036,gae_lambda=0.9693,gamma=0.9884,learning_rate=0.0001,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204308.2878,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204333,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00003\",\n    \"date\": \"2025-11-03_15-12-13\",\n    \"time_this_iter_s\": 25.158924102783203,\n    \"time_total_s\": 25.158924102783203,\n    \"pid\": 94732,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00012485682348698199,\n      \"n_steps\": 512,\n      \"batch_size\": 64,\n      \"gamma\": 0.9884010882947512,\n      \"gae_lambda\": 0.9693100526763685,\n      \"clip_range\": 0.10953605650972704,\n      \"ent_coef\": 0.0035585686132270705,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 25.158924102783203,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_batch_size=64,clip_range=0.1095,ent_coef=0.0036,gae_lambda=0.9693,gamma=0.9884,learning_rate=0.0001,n_steps=512\"\n  },\n  \"last_result_time\": 1762204333.449337,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 25.158924102783203,\n      \"min\": 25.158924102783203,\n      \"avg\": 25.158924102783203,\n      \"last\": 25.158924102783203,\n      \"last-5-avg\": 25.158924102783203,\n      \"last-10-avg\": 25.158924102783203\n    },\n    \"time_total_s\": {\n      \"max\": 25.158924102783203,\n      \"min\": 25.158924102783203,\n      \"avg\": 25.158924102783203,\n      \"last\": 25.158924102783203,\n      \"last-5-avg\": 25.158924102783203,\n      \"last-10-avg\": 25.158924102783203\n    },\n    \"time_since_restore\": {\n      \"max\": 25.158924102783203,\n      \"min\": 25.158924102783203,\n      \"avg\": 25.158924102783203,\n      \"last\": 25.158924102783203,\n      \"last-5-avg\": 25.158924102783203,\n      \"last-10-avg\": 25.158924102783203\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403928af40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403928af40000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403928af40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403928af40000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403928af40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403928af40000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00010\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303031305f31305f62617463685f73697a653d3132382c636c69705f72616e67653d302e313736362c656e745f636f65663d302e303031362c6761655f6c616d6264613d302e393235312c67616d6d613d302e393731352c6c6561726e696e675f726174653d302e303030312c6e5f73745f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 7.890127599032392e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9715281535145732,\n    \"gae_lambda\": 0.9251088120123049,\n    \"clip_range\": 0.17663389402402543,\n    \"ent_coef\": 0.0016130907257252847,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 7.890127599032392e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9715281535145732,\n    \"gae_lambda\": 0.9251088120123049,\n    \"clip_range\": 0.17663389402402543,\n    \"ent_coef\": 0.0016130907257252847,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 7.890127599032392e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9715281535145732,\n    \"gae_lambda\": 0.9251088120123049,\n    \"clip_range\": 0.17663389402402543,\n    \"ent_coef\": 0.0016130907257252847\n  },\n  \"experiment_tag\": \"10_batch_size=128,clip_range=0.1766,ent_coef=0.0016,gae_lambda=0.9251,gamma=0.9715,learning_rate=0.0001,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00010_10_batch_size=128,clip_range=0.1766,ent_coef=0.0016,gae_lambda=0.9251,gamma=0.9715,learning_rate=0.0001,n_st_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204372.319333,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204391,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00010\",\n    \"date\": \"2025-11-03_15-13-11\",\n    \"time_this_iter_s\": 18.904693126678467,\n    \"time_total_s\": 18.904693126678467,\n    \"pid\": 94775,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 7.890127599032392e-05,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9715281535145732,\n      \"gae_lambda\": 0.9251088120123049,\n      \"clip_range\": 0.17663389402402543,\n      \"ent_coef\": 0.0016130907257252847,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 18.904693126678467,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_batch_size=128,clip_range=0.1766,ent_coef=0.0016,gae_lambda=0.9251,gamma=0.9715,learning_rate=0.0001,n_steps=1024\"\n  },\n  \"last_result_time\": 1762204391.2268429,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 18.904693126678467,\n      \"min\": 18.904693126678467,\n      \"avg\": 18.904693126678467,\n      \"last\": 18.904693126678467,\n      \"last-5-avg\": 18.904693126678467,\n      \"last-10-avg\": 18.904693126678467\n    },\n    \"time_total_s\": {\n      \"max\": 18.904693126678467,\n      \"min\": 18.904693126678467,\n      \"avg\": 18.904693126678467,\n      \"last\": 18.904693126678467,\n      \"last-5-avg\": 18.904693126678467,\n      \"last-10-avg\": 18.904693126678467\n    },\n    \"time_since_restore\": {\n      \"max\": 18.904693126678467,\n      \"min\": 18.904693126678467,\n      \"avg\": 18.904693126678467,\n      \"last\": 18.904693126678467,\n      \"last-5-avg\": 18.904693126678467,\n      \"last-10-avg\": 18.904693126678467\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474032e799f8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474032e799f8000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474032e799f8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474032e799f8000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474032e799f8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474032e799f8000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00009\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030395f395f62617463685f73697a653d3132382c636c69705f72616e67653d302e313039382c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393638312c67616d6d613d302e393933322c6c6561726e696e675f726174653d302e303030322c6e5f7374655f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00019395056652150974,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9932303551110415,\n    \"gae_lambda\": 0.9681222181145587,\n    \"clip_range\": 0.10982912510881962,\n    \"ent_coef\": 1.4646438250827051e-06,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00019395056652150974,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9932303551110415,\n    \"gae_lambda\": 0.9681222181145587,\n    \"clip_range\": 0.10982912510881962,\n    \"ent_coef\": 1.4646438250827051e-06,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00019395056652150974,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9932303551110415,\n    \"gae_lambda\": 0.9681222181145587,\n    \"clip_range\": 0.10982912510881962,\n    \"ent_coef\": 1.4646438250827051e-06\n  },\n  \"experiment_tag\": \"9_batch_size=128,clip_range=0.1098,ent_coef=0.0000,gae_lambda=0.9681,gamma=0.9932,learning_rate=0.0002,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00009_9_batch_size=128,clip_range=0.1098,ent_coef=0.0000,gae_lambda=0.9681,gamma=0.9932,learning_rate=0.0002,n_ste_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204370.550407,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204389,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00009\",\n    \"date\": \"2025-11-03_15-13-09\",\n    \"time_this_iter_s\": 19.363709926605225,\n    \"time_total_s\": 19.363709926605225,\n    \"pid\": 94772,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00019395056652150974,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9932303551110415,\n      \"gae_lambda\": 0.9681222181145587,\n      \"clip_range\": 0.10982912510881962,\n      \"ent_coef\": 1.4646438250827051e-06,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 19.363709926605225,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_batch_size=128,clip_range=0.1098,ent_coef=0.0000,gae_lambda=0.9681,gamma=0.9932,learning_rate=0.0002,n_steps=1024\"\n  },\n  \"last_result_time\": 1762204389.9165099,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 19.363709926605225,\n      \"min\": 19.363709926605225,\n      \"avg\": 19.363709926605225,\n      \"last\": 19.363709926605225,\n      \"last-5-avg\": 19.363709926605225,\n      \"last-10-avg\": 19.363709926605225\n    },\n    \"time_total_s\": {\n      \"max\": 19.363709926605225,\n      \"min\": 19.363709926605225,\n      \"avg\": 19.363709926605225,\n      \"last\": 19.363709926605225,\n      \"last-5-avg\": 19.363709926605225,\n      \"last-10-avg\": 19.363709926605225\n    },\n    \"time_since_restore\": {\n      \"max\": 19.363709926605225,\n      \"min\": 19.363709926605225,\n      \"avg\": 19.363709926605225,\n      \"last\": 19.363709926605225,\n      \"last-5-avg\": 19.363709926605225,\n      \"last-10-avg\": 19.363709926605225\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740335d1c18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740335d1c18000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740335d1c18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740335d1c18000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740335d1c18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740335d1c18000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00007\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030375f375f62617463685f73697a653d33322c636c69705f72616e67653d302e313533392c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393231372c67616d6d613d302e393633382c6c6561726e696e675f726174653d302e303030332c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0002938211681667569,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9637948787511124,\n    \"gae_lambda\": 0.9217499482529585,\n    \"clip_range\": 0.15388633221330675,\n    \"ent_coef\": 2.5761751477649947e-05,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0002938211681667569,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9637948787511124,\n    \"gae_lambda\": 0.9217499482529585,\n    \"clip_range\": 0.15388633221330675,\n    \"ent_coef\": 2.5761751477649947e-05,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0002938211681667569,\n    \"n_steps\": 256,\n    \"batch_size\": 32,\n    \"gamma\": 0.9637948787511124,\n    \"gae_lambda\": 0.9217499482529585,\n    \"clip_range\": 0.15388633221330675,\n    \"ent_coef\": 2.5761751477649947e-05\n  },\n  \"experiment_tag\": \"7_batch_size=32,clip_range=0.1539,ent_coef=0.0000,gae_lambda=0.9217,gamma=0.9638,learning_rate=0.0003,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00007_7_batch_size=32,clip_range=0.1539,ent_coef=0.0000,gae_lambda=0.9217,gamma=0.9638,learning_rate=0.0003,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204345.510842,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762204380,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00007\",\n    \"date\": \"2025-11-03_15-13-00\",\n    \"time_this_iter_s\": 34.67497897148132,\n    \"time_total_s\": 34.67497897148132,\n    \"pid\": 94760,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0002938211681667569,\n      \"n_steps\": 256,\n      \"batch_size\": 32,\n      \"gamma\": 0.9637948787511124,\n      \"gae_lambda\": 0.9217499482529585,\n      \"clip_range\": 0.15388633221330675,\n      \"ent_coef\": 2.5761751477649947e-05,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 34.67497897148132,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_batch_size=32,clip_range=0.1539,ent_coef=0.0000,gae_lambda=0.9217,gamma=0.9638,learning_rate=0.0003,n_steps=256\"\n  },\n  \"last_result_time\": 1762204380.189027,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.67497897148132,\n      \"min\": 34.67497897148132,\n      \"avg\": 34.67497897148132,\n      \"last\": 34.67497897148132,\n      \"last-5-avg\": 34.67497897148132,\n      \"last-10-avg\": 34.67497897148132\n    },\n    \"time_total_s\": {\n      \"max\": 34.67497897148132,\n      \"min\": 34.67497897148132,\n      \"avg\": 34.67497897148132,\n      \"last\": 34.67497897148132,\n      \"last-5-avg\": 34.67497897148132,\n      \"last-10-avg\": 34.67497897148132\n    },\n    \"time_since_restore\": {\n      \"max\": 34.67497897148132,\n      \"min\": 34.67497897148132,\n      \"avg\": 34.67497897148132,\n      \"last\": 34.67497897148132,\n      \"last-5-avg\": 34.67497897148132,\n      \"last-10-avg\": 34.67497897148132\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740415665b6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740415665b6000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740415665b6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740415665b6000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740415665b6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740415665b6000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00002\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030325f325f62617463685f73697a653d3132382c636c69705f72616e67653d302e323037302c656e745f636f65663d302e303037362c6761655f6c616d6264613d302e393231372c67616d6d613d302e393933392c6c6561726e696e675f726174653d302e303030312c6e5f7374655f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 6.244150884284019e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9939167729404195,\n    \"gae_lambda\": 0.921741669428796,\n    \"clip_range\": 0.20697998992248007,\n    \"ent_coef\": 0.0075902109549681,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 6.244150884284019e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9939167729404195,\n    \"gae_lambda\": 0.921741669428796,\n    \"clip_range\": 0.20697998992248007,\n    \"ent_coef\": 0.0075902109549681,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 6.244150884284019e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 128,\n    \"gamma\": 0.9939167729404195,\n    \"gae_lambda\": 0.921741669428796,\n    \"clip_range\": 0.20697998992248007,\n    \"ent_coef\": 0.0075902109549681\n  },\n  \"experiment_tag\": \"2_batch_size=128,clip_range=0.2070,ent_coef=0.0076,gae_lambda=0.9217,gamma=0.9939,learning_rate=0.0001,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00002_2_batch_size=128,clip_range=0.2070,ent_coef=0.0076,gae_lambda=0.9217,gamma=0.9939,learning_rate=0.0001,n_ste_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204308.289632,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 343.4,\n    \"timestamp\": 1762204327,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00002\",\n    \"date\": \"2025-11-03_15-12-07\",\n    \"time_this_iter_s\": 19.579368352890015,\n    \"time_total_s\": 19.579368352890015,\n    \"pid\": 94729,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 6.244150884284019e-05,\n      \"n_steps\": 1024,\n      \"batch_size\": 128,\n      \"gamma\": 0.9939167729404195,\n      \"gae_lambda\": 0.921741669428796,\n      \"clip_range\": 0.20697998992248007,\n      \"ent_coef\": 0.0075902109549681,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 19.579368352890015,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_batch_size=128,clip_range=0.2070,ent_coef=0.0076,gae_lambda=0.9217,gamma=0.9939,learning_rate=0.0001,n_steps=1024\"\n  },\n  \"last_result_time\": 1762204327.871951,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 343.4,\n      \"min\": 343.4,\n      \"avg\": 343.4,\n      \"last\": 343.4,\n      \"last-5-avg\": 343.4,\n      \"last-10-avg\": 343.4\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 19.579368352890015,\n      \"min\": 19.579368352890015,\n      \"avg\": 19.579368352890015,\n      \"last\": 19.579368352890015,\n      \"last-5-avg\": 19.579368352890015,\n      \"last-10-avg\": 19.579368352890015\n    },\n    \"time_total_s\": {\n      \"max\": 19.579368352890015,\n      \"min\": 19.579368352890015,\n      \"avg\": 19.579368352890015,\n      \"last\": 19.579368352890015,\n      \"last-5-avg\": 19.579368352890015,\n      \"last-10-avg\": 19.579368352890015\n    },\n    \"time_since_restore\": {\n      \"max\": 19.579368352890015,\n      \"min\": 19.579368352890015,\n      \"avg\": 19.579368352890015,\n      \"last\": 19.579368352890015,\n      \"last-5-avg\": 19.579368352890015,\n      \"last-10-avg\": 19.579368352890015\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075766666666666612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075766666666666612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403394517c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403394517c000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403394517c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403394517c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403394517c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403394517c000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"b4d0d_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d31312d3436948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f62346430645f30303030305f305f62617463685f73697a653d36342c636c69705f72616e67653d302e313933392c656e745f636f65663d302e303033342c6761655f6c616d6264613d302e393032302c67616d6d613d302e393530352c6c6561726e696e675f726174653d302e303030302c6e5f737465705f323032352d31312d30335f31352d31312d3436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d31312d34369475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 1.1473527684823824e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9504535673517348,\n    \"gae_lambda\": 0.902033746966521,\n    \"clip_range\": 0.19385415827751773,\n    \"ent_coef\": 0.0034264508638652226,\n    \"total_timesteps\": 100000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 1.1473527684823824e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9504535673517348,\n    \"gae_lambda\": 0.902033746966521,\n    \"clip_range\": 0.19385415827751773,\n    \"ent_coef\": 0.0034264508638652226,\n    \"total_timesteps\": 100000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 1.1473527684823824e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9504535673517348,\n    \"gae_lambda\": 0.902033746966521,\n    \"clip_range\": 0.19385415827751773,\n    \"ent_coef\": 0.0034264508638652226\n  },\n  \"experiment_tag\": \"0_batch_size=64,clip_range=0.1939,ent_coef=0.0034,gae_lambda=0.9020,gamma=0.9505,learning_rate=0.0000,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_b4d0d_00000_0_batch_size=64,clip_range=0.1939,ent_coef=0.0034,gae_lambda=0.9020,gamma=0.9505,learning_rate=0.0000,n_step_2025-11-03_15-11-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762204308.243552,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 424.8,\n    \"timestamp\": 1762204333,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4d0d_00000\",\n    \"date\": \"2025-11-03_15-12-13\",\n    \"time_this_iter_s\": 25.277992010116577,\n    \"time_total_s\": 25.277992010116577,\n    \"pid\": 94730,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1.1473527684823824e-05,\n      \"n_steps\": 512,\n      \"batch_size\": 64,\n      \"gamma\": 0.9504535673517348,\n      \"gae_lambda\": 0.902033746966521,\n      \"clip_range\": 0.19385415827751773,\n      \"ent_coef\": 0.0034264508638652226,\n      \"total_timesteps\": 100000\n    },\n    \"time_since_restore\": 25.277992010116577,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"0_batch_size=64,clip_range=0.1939,ent_coef=0.0034,gae_lambda=0.9020,gamma=0.9505,learning_rate=0.0000,n_steps=512\"\n  },\n  \"last_result_time\": 1762204333.5247731,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 424.8,\n      \"min\": 424.8,\n      \"avg\": 424.8,\n      \"last\": 424.8,\n      \"last-5-avg\": 424.8,\n      \"last-10-avg\": 424.8\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 25.277992010116577,\n      \"min\": 25.277992010116577,\n      \"avg\": 25.277992010116577,\n      \"last\": 25.277992010116577,\n      \"last-5-avg\": 25.277992010116577,\n      \"last-10-avg\": 25.277992010116577\n    },\n    \"time_total_s\": {\n      \"max\": 25.277992010116577,\n      \"min\": 25.277992010116577,\n      \"avg\": 25.277992010116577,\n      \"last\": 25.277992010116577,\n      \"last-5-avg\": 25.277992010116577,\n      \"last-10-avg\": 25.277992010116577\n    },\n    \"time_since_restore\": {\n      \"max\": 25.277992010116577,\n      \"min\": 25.277992010116577,\n      \"avg\": 25.277992010116577,\n      \"last\": 25.277992010116577,\n      \"last-5-avg\": 25.277992010116577,\n      \"last-10-avg\": 25.277992010116577\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407a8ccccccccccd612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407a8ccccccccccd612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039472a7c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039472a7c000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039472a7c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039472a7c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039472a7c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039472a7c000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 390852.195164166, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": "mean_reward", "_total_time": 662.5712685585022, "_iteration": 1056, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1762204306.8487968, "_session_str": "2025-11-03_15-11-46", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1762204306.8487968}}