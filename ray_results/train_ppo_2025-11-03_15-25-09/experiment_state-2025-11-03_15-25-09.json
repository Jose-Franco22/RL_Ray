{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00011\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303031315f31315f62617463685f73697a653d36342c636c69705f72616e67653d302e323832332c656e745f636f65663d302e303038352c6761655f6c616d6264613d302e393431342c67616d6d613d302e393737382c6c6561726e696e675f726174653d302e303030342c6e5f7374655f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.000434860865170356,\n    \"n_steps\": 256,\n    \"batch_size\": 64,\n    \"gamma\": 0.977778550975506,\n    \"gae_lambda\": 0.9413751916278266,\n    \"clip_range\": 0.2822775866392989,\n    \"ent_coef\": 0.008454803087491929,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.000434860865170356,\n    \"n_steps\": 256,\n    \"batch_size\": 64,\n    \"gamma\": 0.977778550975506,\n    \"gae_lambda\": 0.9413751916278266,\n    \"clip_range\": 0.2822775866392989,\n    \"ent_coef\": 0.008454803087491929,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.000434860865170356,\n    \"n_steps\": 256,\n    \"batch_size\": 64,\n    \"gamma\": 0.977778550975506,\n    \"gae_lambda\": 0.9413751916278266,\n    \"clip_range\": 0.2822775866392989,\n    \"ent_coef\": 0.008454803087491929\n  },\n  \"experiment_tag\": \"11_batch_size=64,clip_range=0.2823,ent_coef=0.0085,gae_lambda=0.9414,gamma=0.9778,learning_rate=0.0004,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00011_11_batch_size=64,clip_range=0.2823,ent_coef=0.0085,gae_lambda=0.9414,gamma=0.9778,learning_rate=0.0004,n_ste_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205385.931511,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205503,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00011\",\n    \"date\": \"2025-11-03_15-31-43\",\n    \"time_this_iter_s\": 117.36068987846375,\n    \"time_total_s\": 117.36068987846375,\n    \"pid\": 95233,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.000434860865170356,\n      \"n_steps\": 256,\n      \"batch_size\": 64,\n      \"gamma\": 0.977778550975506,\n      \"gae_lambda\": 0.9413751916278266,\n      \"clip_range\": 0.2822775866392989,\n      \"ent_coef\": 0.008454803087491929,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 117.36068987846375,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11_batch_size=64,clip_range=0.2823,ent_coef=0.0085,gae_lambda=0.9414,gamma=0.9778,learning_rate=0.0004,n_steps=256\"\n  },\n  \"last_result_time\": 1762205503.2947268,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 117.36068987846375,\n      \"min\": 117.36068987846375,\n      \"avg\": 117.36068987846375,\n      \"last\": 117.36068987846375,\n      \"last-5-avg\": 117.36068987846375,\n      \"last-10-avg\": 117.36068987846375\n    },\n    \"time_total_s\": {\n      \"max\": 117.36068987846375,\n      \"min\": 117.36068987846375,\n      \"avg\": 117.36068987846375,\n      \"last\": 117.36068987846375,\n      \"last-5-avg\": 117.36068987846375,\n      \"last-10-avg\": 117.36068987846375\n    },\n    \"time_since_restore\": {\n      \"max\": 117.36068987846375,\n      \"min\": 117.36068987846375,\n      \"avg\": 117.36068987846375,\n      \"last\": 117.36068987846375,\n      \"last-5-avg\": 117.36068987846375,\n      \"last-10-avg\": 117.36068987846375\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d57158b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d57158b000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d57158b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d57158b000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d57158b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d57158b000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00008\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030385f385f62617463685f73697a653d3132382c636c69705f72616e67653d302e313233392c656e745f636f65663d302e303033322c6761655f6c616d6264613d302e393235302c67616d6d613d302e393834342c6c6561726e696e675f726174653d302e303030302c6e5f7374655f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 2.58534369395747e-05,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.9844008418424176,\n    \"gae_lambda\": 0.9250036006179592,\n    \"clip_range\": 0.12389086601702015,\n    \"ent_coef\": 0.0032298226389877393,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 2.58534369395747e-05,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.9844008418424176,\n    \"gae_lambda\": 0.9250036006179592,\n    \"clip_range\": 0.12389086601702015,\n    \"ent_coef\": 0.0032298226389877393,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 2.58534369395747e-05,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.9844008418424176,\n    \"gae_lambda\": 0.9250036006179592,\n    \"clip_range\": 0.12389086601702015,\n    \"ent_coef\": 0.0032298226389877393\n  },\n  \"experiment_tag\": \"8_batch_size=128,clip_range=0.1239,ent_coef=0.0032,gae_lambda=0.9250,gamma=0.9844,learning_rate=0.0000,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00008_8_batch_size=128,clip_range=0.1239,ent_coef=0.0032,gae_lambda=0.9250,gamma=0.9844,learning_rate=0.0000,n_ste_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205357.9058702,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 427.2,\n    \"timestamp\": 1762205454,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00008\",\n    \"date\": \"2025-11-03_15-30-54\",\n    \"time_this_iter_s\": 96.70001411437988,\n    \"time_total_s\": 96.70001411437988,\n    \"pid\": 95218,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 2.58534369395747e-05,\n      \"n_steps\": 256,\n      \"batch_size\": 128,\n      \"gamma\": 0.9844008418424176,\n      \"gae_lambda\": 0.9250036006179592,\n      \"clip_range\": 0.12389086601702015,\n      \"ent_coef\": 0.0032298226389877393,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 96.70001411437988,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_batch_size=128,clip_range=0.1239,ent_coef=0.0032,gae_lambda=0.9250,gamma=0.9844,learning_rate=0.0000,n_steps=256\"\n  },\n  \"last_result_time\": 1762205454.608605,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 427.2,\n      \"min\": 427.2,\n      \"avg\": 427.2,\n      \"last\": 427.2,\n      \"last-5-avg\": 427.2,\n      \"last-10-avg\": 427.2\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 96.70001411437988,\n      \"min\": 96.70001411437988,\n      \"avg\": 96.70001411437988,\n      \"last\": 96.70001411437988,\n      \"last-5-avg\": 96.70001411437988,\n      \"last-10-avg\": 96.70001411437988\n    },\n    \"time_total_s\": {\n      \"max\": 96.70001411437988,\n      \"min\": 96.70001411437988,\n      \"avg\": 96.70001411437988,\n      \"last\": 96.70001411437988,\n      \"last-5-avg\": 96.70001411437988,\n      \"last-10-avg\": 96.70001411437988\n    },\n    \"time_since_restore\": {\n      \"max\": 96.70001411437988,\n      \"min\": 96.70001411437988,\n      \"avg\": 96.70001411437988,\n      \"last\": 96.70001411437988,\n      \"last-5-avg\": 96.70001411437988,\n      \"last-10-avg\": 96.70001411437988\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407ab33333333333612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407ab33333333333612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740582ccd08000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740582ccd08000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740582ccd08000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740582ccd08000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740582ccd08000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740582ccd08000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00010\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303031305f31305f62617463685f73697a653d36342c636c69705f72616e67653d302e313231392c656e745f636f65663d302e303030312c6761655f6c616d6264613d302e393230342c67616d6d613d302e393635342c6c6561726e696e675f726174653d302e303030302c6e5f7374655f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 2.621828876939846e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.96539359498394,\n    \"gae_lambda\": 0.9204271674161101,\n    \"clip_range\": 0.12194699080186136,\n    \"ent_coef\": 5.4708258897115286e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 2.621828876939846e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.96539359498394,\n    \"gae_lambda\": 0.9204271674161101,\n    \"clip_range\": 0.12194699080186136,\n    \"ent_coef\": 5.4708258897115286e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 2.621828876939846e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.96539359498394,\n    \"gae_lambda\": 0.9204271674161101,\n    \"clip_range\": 0.12194699080186136,\n    \"ent_coef\": 5.4708258897115286e-05\n  },\n  \"experiment_tag\": \"10_batch_size=64,clip_range=0.1219,ent_coef=0.0001,gae_lambda=0.9204,gamma=0.9654,learning_rate=0.0000,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00010_10_batch_size=64,clip_range=0.1219,ent_coef=0.0001,gae_lambda=0.9204,gamma=0.9654,learning_rate=0.0000,n_ste_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205384.049221,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205500,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00010\",\n    \"date\": \"2025-11-03_15-31-40\",\n    \"time_this_iter_s\": 116.79580807685852,\n    \"time_total_s\": 116.79580807685852,\n    \"pid\": 95231,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 2.621828876939846e-05,\n      \"n_steps\": 1024,\n      \"batch_size\": 64,\n      \"gamma\": 0.96539359498394,\n      \"gae_lambda\": 0.9204271674161101,\n      \"clip_range\": 0.12194699080186136,\n      \"ent_coef\": 5.4708258897115286e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 116.79580807685852,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_batch_size=64,clip_range=0.1219,ent_coef=0.0001,gae_lambda=0.9204,gamma=0.9654,learning_rate=0.0000,n_steps=1024\"\n  },\n  \"last_result_time\": 1762205500.847418,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 116.79580807685852,\n      \"min\": 116.79580807685852,\n      \"avg\": 116.79580807685852,\n      \"last\": 116.79580807685852,\n      \"last-5-avg\": 116.79580807685852,\n      \"last-10-avg\": 116.79580807685852\n    },\n    \"time_total_s\": {\n      \"max\": 116.79580807685852,\n      \"min\": 116.79580807685852,\n      \"avg\": 116.79580807685852,\n      \"last\": 116.79580807685852,\n      \"last-5-avg\": 116.79580807685852,\n      \"last-10-avg\": 116.79580807685852\n    },\n    \"time_since_restore\": {\n      \"max\": 116.79580807685852,\n      \"min\": 116.79580807685852,\n      \"avg\": 116.79580807685852,\n      \"last\": 116.79580807685852,\n      \"last-5-avg\": 116.79580807685852,\n      \"last-10-avg\": 116.79580807685852\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d32ee85000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d32ee85000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d32ee85000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d32ee85000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d32ee85000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d32ee85000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00004\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030345f345f62617463685f73697a653d33322c636c69705f72616e67653d302e323130392c656e745f636f65663d302e303030312c6761655f6c616d6264613d302e393435302c67616d6d613d302e393531332c6c6561726e696e675f726174653d302e303030302c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 1.8513435892218862e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 32,\n    \"gamma\": 0.9512586639591298,\n    \"gae_lambda\": 0.9449565258878406,\n    \"clip_range\": 0.21087083550083624,\n    \"ent_coef\": 7.108621825703449e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 1.8513435892218862e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 32,\n    \"gamma\": 0.9512586639591298,\n    \"gae_lambda\": 0.9449565258878406,\n    \"clip_range\": 0.21087083550083624,\n    \"ent_coef\": 7.108621825703449e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 1.8513435892218862e-05,\n    \"n_steps\": 512,\n    \"batch_size\": 32,\n    \"gamma\": 0.9512586639591298,\n    \"gae_lambda\": 0.9449565258878406,\n    \"clip_range\": 0.21087083550083624,\n    \"ent_coef\": 7.108621825703449e-05\n  },\n  \"experiment_tag\": \"4_batch_size=32,clip_range=0.2109,ent_coef=0.0001,gae_lambda=0.9450,gamma=0.9513,learning_rate=0.0000,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00004_4_batch_size=32,clip_range=0.2109,ent_coef=0.0001,gae_lambda=0.9450,gamma=0.9513,learning_rate=0.0000,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205211.743971,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205381,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00004\",\n    \"date\": \"2025-11-03_15-29-41\",\n    \"time_this_iter_s\": 169.73031616210938,\n    \"time_total_s\": 169.73031616210938,\n    \"pid\": 95145,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1.8513435892218862e-05,\n      \"n_steps\": 512,\n      \"batch_size\": 32,\n      \"gamma\": 0.9512586639591298,\n      \"gae_lambda\": 0.9449565258878406,\n      \"clip_range\": 0.21087083550083624,\n      \"ent_coef\": 7.108621825703449e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 169.73031616210938,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_batch_size=32,clip_range=0.2109,ent_coef=0.0001,gae_lambda=0.9450,gamma=0.9513,learning_rate=0.0000,n_steps=512\"\n  },\n  \"last_result_time\": 1762205381.477083,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 169.73031616210938,\n      \"min\": 169.73031616210938,\n      \"avg\": 169.73031616210938,\n      \"last\": 169.73031616210938,\n      \"last-5-avg\": 169.73031616210938,\n      \"last-10-avg\": 169.73031616210938\n    },\n    \"time_total_s\": {\n      \"max\": 169.73031616210938,\n      \"min\": 169.73031616210938,\n      \"avg\": 169.73031616210938,\n      \"last\": 169.73031616210938,\n      \"last-5-avg\": 169.73031616210938,\n      \"last-10-avg\": 169.73031616210938\n    },\n    \"time_since_restore\": {\n      \"max\": 169.73031616210938,\n      \"min\": 169.73031616210938,\n      \"avg\": 169.73031616210938,\n      \"last\": 169.73031616210938,\n      \"last-5-avg\": 169.73031616210938,\n      \"last-10-avg\": 169.73031616210938\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474065375ec0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474065375ec0000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474065375ec0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474065375ec0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474065375ec0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474065375ec0000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00001\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030315f315f62617463685f73697a653d36342c636c69705f72616e67653d302e323337322c656e745f636f65663d302e303039312c6761655f6c616d6264613d302e393439322c67616d6d613d302e393936382c6c6561726e696e675f726174653d302e303030322c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00021728472115872165,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.9968431157740928,\n    \"gae_lambda\": 0.9492144011041342,\n    \"clip_range\": 0.23717814143833515,\n    \"ent_coef\": 0.00914444636908991,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00021728472115872165,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.9968431157740928,\n    \"gae_lambda\": 0.9492144011041342,\n    \"clip_range\": 0.23717814143833515,\n    \"ent_coef\": 0.00914444636908991,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00021728472115872165,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.9968431157740928,\n    \"gae_lambda\": 0.9492144011041342,\n    \"clip_range\": 0.23717814143833515,\n    \"ent_coef\": 0.00914444636908991\n  },\n  \"experiment_tag\": \"1_batch_size=64,clip_range=0.2372,ent_coef=0.0091,gae_lambda=0.9492,gamma=0.9968,learning_rate=0.0002,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00001_1_batch_size=64,clip_range=0.2372,ent_coef=0.0091,gae_lambda=0.9492,gamma=0.9968,learning_rate=0.0002,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205111.254385,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205234,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00001\",\n    \"date\": \"2025-11-03_15-27-14\",\n    \"time_this_iter_s\": 123.58875012397766,\n    \"time_total_s\": 123.58875012397766,\n    \"pid\": 95096,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00021728472115872165,\n      \"n_steps\": 1024,\n      \"batch_size\": 64,\n      \"gamma\": 0.9968431157740928,\n      \"gae_lambda\": 0.9492144011041342,\n      \"clip_range\": 0.23717814143833515,\n      \"ent_coef\": 0.00914444636908991,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 123.58875012397766,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_batch_size=64,clip_range=0.2372,ent_coef=0.0091,gae_lambda=0.9492,gamma=0.9968,learning_rate=0.0002,n_steps=1024\"\n  },\n  \"last_result_time\": 1762205234.8457391,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 123.58875012397766,\n      \"min\": 123.58875012397766,\n      \"avg\": 123.58875012397766,\n      \"last\": 123.58875012397766,\n      \"last-5-avg\": 123.58875012397766,\n      \"last-10-avg\": 123.58875012397766\n    },\n    \"time_total_s\": {\n      \"max\": 123.58875012397766,\n      \"min\": 123.58875012397766,\n      \"avg\": 123.58875012397766,\n      \"last\": 123.58875012397766,\n      \"last-5-avg\": 123.58875012397766,\n      \"last-10-avg\": 123.58875012397766\n    },\n    \"time_since_restore\": {\n      \"max\": 123.58875012397766,\n      \"min\": 123.58875012397766,\n      \"avg\": 123.58875012397766,\n      \"last\": 123.58875012397766,\n      \"last-5-avg\": 123.58875012397766,\n      \"last-10-avg\": 123.58875012397766\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ee5ae15000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ee5ae15000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ee5ae15000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ee5ae15000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ee5ae15000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ee5ae15000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030305f305f62617463685f73697a653d33322c636c69705f72616e67653d302e313032322c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393831392c67616d6d613d302e393834362c6c6561726e696e675f726174653d302e303030302c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 1.3992565968011976e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 32,\n    \"gamma\": 0.9845570236256728,\n    \"gae_lambda\": 0.9818667258231166,\n    \"clip_range\": 0.10217828880415769,\n    \"ent_coef\": 5.267100857758376e-06,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 1.3992565968011976e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 32,\n    \"gamma\": 0.9845570236256728,\n    \"gae_lambda\": 0.9818667258231166,\n    \"clip_range\": 0.10217828880415769,\n    \"ent_coef\": 5.267100857758376e-06,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 1.3992565968011976e-05,\n    \"n_steps\": 1024,\n    \"batch_size\": 32,\n    \"gamma\": 0.9845570236256728,\n    \"gae_lambda\": 0.9818667258231166,\n    \"clip_range\": 0.10217828880415769,\n    \"ent_coef\": 5.267100857758376e-06\n  },\n  \"experiment_tag\": \"0_batch_size=32,clip_range=0.1022,ent_coef=0.0000,gae_lambda=0.9819,gamma=0.9846,learning_rate=0.0000,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00000_0_batch_size=32,clip_range=0.1022,ent_coef=0.0000,gae_lambda=0.9819,gamma=0.9846,learning_rate=0.0000,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205111.1973262,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 495.8,\n    \"timestamp\": 1762205284,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00000\",\n    \"date\": \"2025-11-03_15-28-04\",\n    \"time_this_iter_s\": 173.03944325447083,\n    \"time_total_s\": 173.03944325447083,\n    \"pid\": 95093,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1.3992565968011976e-05,\n      \"n_steps\": 1024,\n      \"batch_size\": 32,\n      \"gamma\": 0.9845570236256728,\n      \"gae_lambda\": 0.9818667258231166,\n      \"clip_range\": 0.10217828880415769,\n      \"ent_coef\": 5.267100857758376e-06,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 173.03944325447083,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"0_batch_size=32,clip_range=0.1022,ent_coef=0.0000,gae_lambda=0.9819,gamma=0.9846,learning_rate=0.0000,n_steps=1024\"\n  },\n  \"last_result_time\": 1762205284.2403572,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 495.8,\n      \"min\": 495.8,\n      \"avg\": 495.8,\n      \"last\": 495.8,\n      \"last-5-avg\": 495.8,\n      \"last-10-avg\": 495.8\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 173.03944325447083,\n      \"min\": 173.03944325447083,\n      \"avg\": 173.03944325447083,\n      \"last\": 173.03944325447083,\n      \"last-5-avg\": 173.03944325447083,\n      \"last-10-avg\": 173.03944325447083\n    },\n    \"time_total_s\": {\n      \"max\": 173.03944325447083,\n      \"min\": 173.03944325447083,\n      \"avg\": 173.03944325447083,\n      \"last\": 173.03944325447083,\n      \"last-5-avg\": 173.03944325447083,\n      \"last-10-avg\": 173.03944325447083\n    },\n    \"time_since_restore\": {\n      \"max\": 173.03944325447083,\n      \"min\": 173.03944325447083,\n      \"avg\": 173.03944325447083,\n      \"last\": 173.03944325447083,\n      \"last-5-avg\": 173.03944325447083,\n      \"last-10-avg\": 173.03944325447083\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407efccccccccccd612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407efccccccccccd612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474065a1431e800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474065a1431e800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474065a1431e800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474065a1431e800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474065a1431e800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474065a1431e800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00003\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030335f335f62617463685f73697a653d36342c636c69705f72616e67653d302e323535312c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393737382c67616d6d613d302e393733342c6c6561726e696e675f726174653d302e303030372c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0007383149808306804,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9733831662279109,\n    \"gae_lambda\": 0.9778030548791126,\n    \"clip_range\": 0.2550589640288491,\n    \"ent_coef\": 6.160174602483059e-06,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0007383149808306804,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9733831662279109,\n    \"gae_lambda\": 0.9778030548791126,\n    \"clip_range\": 0.2550589640288491,\n    \"ent_coef\": 6.160174602483059e-06,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0007383149808306804,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9733831662279109,\n    \"gae_lambda\": 0.9778030548791126,\n    \"clip_range\": 0.2550589640288491,\n    \"ent_coef\": 6.160174602483059e-06\n  },\n  \"experiment_tag\": \"3_batch_size=64,clip_range=0.2551,ent_coef=0.0000,gae_lambda=0.9778,gamma=0.9734,learning_rate=0.0007,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00003_3_batch_size=64,clip_range=0.2551,ent_coef=0.0000,gae_lambda=0.9778,gamma=0.9734,learning_rate=0.0007,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205111.265541,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205235,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00003\",\n    \"date\": \"2025-11-03_15-27-15\",\n    \"time_this_iter_s\": 124.17604517936707,\n    \"time_total_s\": 124.17604517936707,\n    \"pid\": 95095,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0007383149808306804,\n      \"n_steps\": 512,\n      \"batch_size\": 64,\n      \"gamma\": 0.9733831662279109,\n      \"gae_lambda\": 0.9778030548791126,\n      \"clip_range\": 0.2550589640288491,\n      \"ent_coef\": 6.160174602483059e-06,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 124.17604517936707,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_batch_size=64,clip_range=0.2551,ent_coef=0.0000,gae_lambda=0.9778,gamma=0.9734,learning_rate=0.0007,n_steps=512\"\n  },\n  \"last_result_time\": 1762205235.444586,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 124.17604517936707,\n      \"min\": 124.17604517936707,\n      \"avg\": 124.17604517936707,\n      \"last\": 124.17604517936707,\n      \"last-5-avg\": 124.17604517936707,\n      \"last-10-avg\": 124.17604517936707\n    },\n    \"time_total_s\": {\n      \"max\": 124.17604517936707,\n      \"min\": 124.17604517936707,\n      \"avg\": 124.17604517936707,\n      \"last\": 124.17604517936707,\n      \"last-5-avg\": 124.17604517936707,\n      \"last-10-avg\": 124.17604517936707\n    },\n    \"time_since_restore\": {\n      \"max\": 124.17604517936707,\n      \"min\": 124.17604517936707,\n      \"avg\": 124.17604517936707,\n      \"last\": 124.17604517936707,\n      \"last-5-avg\": 124.17604517936707,\n      \"last-10-avg\": 124.17604517936707\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405f0b4453000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405f0b4453000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405f0b4453000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405f0b4453000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405f0b4453000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405f0b4453000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00007\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030375f375f62617463685f73697a653d3132382c636c69705f72616e67653d302e323830342c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393830342c67616d6d613d302e393635322c6c6561726e696e675f726174653d302e303030362c6e5f7374655f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0006031718394758274,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.965218287217409,\n    \"gae_lambda\": 0.9804137088447752,\n    \"clip_range\": 0.28041573460711944,\n    \"ent_coef\": 1.700335508352651e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0006031718394758274,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.965218287217409,\n    \"gae_lambda\": 0.9804137088447752,\n    \"clip_range\": 0.28041573460711944,\n    \"ent_coef\": 1.700335508352651e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0006031718394758274,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.965218287217409,\n    \"gae_lambda\": 0.9804137088447752,\n    \"clip_range\": 0.28041573460711944,\n    \"ent_coef\": 1.700335508352651e-05\n  },\n  \"experiment_tag\": \"7_batch_size=128,clip_range=0.2804,ent_coef=0.0000,gae_lambda=0.9804,gamma=0.9652,learning_rate=0.0006,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00007_7_batch_size=128,clip_range=0.2804,ent_coef=0.0000,gae_lambda=0.9804,gamma=0.9652,learning_rate=0.0006,n_ste_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205286.8161752,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205383,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00007\",\n    \"date\": \"2025-11-03_15-29-43\",\n    \"time_this_iter_s\": 97.00171422958374,\n    \"time_total_s\": 97.00171422958374,\n    \"pid\": 95184,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0006031718394758274,\n      \"n_steps\": 256,\n      \"batch_size\": 128,\n      \"gamma\": 0.965218287217409,\n      \"gae_lambda\": 0.9804137088447752,\n      \"clip_range\": 0.28041573460711944,\n      \"ent_coef\": 1.700335508352651e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 97.00171422958374,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_batch_size=128,clip_range=0.2804,ent_coef=0.0000,gae_lambda=0.9804,gamma=0.9652,learning_rate=0.0006,n_steps=256\"\n  },\n  \"last_result_time\": 1762205383.82141,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 97.00171422958374,\n      \"min\": 97.00171422958374,\n      \"avg\": 97.00171422958374,\n      \"last\": 97.00171422958374,\n      \"last-5-avg\": 97.00171422958374,\n      \"last-10-avg\": 97.00171422958374\n    },\n    \"time_total_s\": {\n      \"max\": 97.00171422958374,\n      \"min\": 97.00171422958374,\n      \"avg\": 97.00171422958374,\n      \"last\": 97.00171422958374,\n      \"last-5-avg\": 97.00171422958374,\n      \"last-10-avg\": 97.00171422958374\n    },\n    \"time_since_restore\": {\n      \"max\": 97.00171422958374,\n      \"min\": 97.00171422958374,\n      \"avg\": 97.00171422958374,\n      \"last\": 97.00171422958374,\n      \"last-5-avg\": 97.00171422958374,\n      \"last-10-avg\": 97.00171422958374\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058401c16000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058401c16000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058401c16000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058401c16000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058401c16000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058401c16000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00005\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030355f355f62617463685f73697a653d36342c636c69705f72616e67653d302e323132342c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393133392c67616d6d613d302e393834372c6c6561726e696e675f726174653d302e303030302c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 4.296578829631603e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 64,\n    \"gamma\": 0.9847064478428966,\n    \"gae_lambda\": 0.913926232745797,\n    \"clip_range\": 0.21239670999401505,\n    \"ent_coef\": 4.375594812335187e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 4.296578829631603e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 64,\n    \"gamma\": 0.9847064478428966,\n    \"gae_lambda\": 0.913926232745797,\n    \"clip_range\": 0.21239670999401505,\n    \"ent_coef\": 4.375594812335187e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 4.296578829631603e-05,\n    \"n_steps\": 128,\n    \"batch_size\": 64,\n    \"gamma\": 0.9847064478428966,\n    \"gae_lambda\": 0.913926232745797,\n    \"clip_range\": 0.21239670999401505,\n    \"ent_coef\": 4.375594812335187e-05\n  },\n  \"experiment_tag\": \"5_batch_size=64,clip_range=0.2124,ent_coef=0.0000,gae_lambda=0.9139,gamma=0.9847,learning_rate=0.0000,n_steps=128\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00005_5_batch_size=64,clip_range=0.2124,ent_coef=0.0000,gae_lambda=0.9139,gamma=0.9847,learning_rate=0.0000,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205236.7408938,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205358,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00005\",\n    \"date\": \"2025-11-03_15-29-18\",\n    \"time_this_iter_s\": 121.93129897117615,\n    \"time_total_s\": 121.93129897117615,\n    \"pid\": 95154,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 4.296578829631603e-05,\n      \"n_steps\": 128,\n      \"batch_size\": 64,\n      \"gamma\": 0.9847064478428966,\n      \"gae_lambda\": 0.913926232745797,\n      \"clip_range\": 0.21239670999401505,\n      \"ent_coef\": 4.375594812335187e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 121.93129897117615,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_batch_size=64,clip_range=0.2124,ent_coef=0.0000,gae_lambda=0.9139,gamma=0.9847,learning_rate=0.0000,n_steps=128\"\n  },\n  \"last_result_time\": 1762205358.6750631,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 121.93129897117615,\n      \"min\": 121.93129897117615,\n      \"avg\": 121.93129897117615,\n      \"last\": 121.93129897117615,\n      \"last-5-avg\": 121.93129897117615,\n      \"last-10-avg\": 121.93129897117615\n    },\n    \"time_total_s\": {\n      \"max\": 121.93129897117615,\n      \"min\": 121.93129897117615,\n      \"avg\": 121.93129897117615,\n      \"last\": 121.93129897117615,\n      \"last-5-avg\": 121.93129897117615,\n      \"last-10-avg\": 121.93129897117615\n    },\n    \"time_since_restore\": {\n      \"max\": 121.93129897117615,\n      \"min\": 121.93129897117615,\n      \"avg\": 121.93129897117615,\n      \"last\": 121.93129897117615,\n      \"last-5-avg\": 121.93129897117615,\n      \"last-10-avg\": 121.93129897117615\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405e7b9a67000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405e7b9a67000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405e7b9a67000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405e7b9a67000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405e7b9a67000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405e7b9a67000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00009\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030395f395f62617463685f73697a653d36342c636c69705f72616e67653d302e313933342c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393038352c67616d6d613d302e393635332c6c6561726e696e675f726174653d302e303030342c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.0004067939702729457,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9652936011469091,\n    \"gae_lambda\": 0.9085335001277214,\n    \"clip_range\": 0.19340286146221553,\n    \"ent_coef\": 2.327857150979202e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.0004067939702729457,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9652936011469091,\n    \"gae_lambda\": 0.9085335001277214,\n    \"clip_range\": 0.19340286146221553,\n    \"ent_coef\": 2.327857150979202e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0004067939702729457,\n    \"n_steps\": 512,\n    \"batch_size\": 64,\n    \"gamma\": 0.9652936011469091,\n    \"gae_lambda\": 0.9085335001277214,\n    \"clip_range\": 0.19340286146221553,\n    \"ent_coef\": 2.327857150979202e-05\n  },\n  \"experiment_tag\": \"9_batch_size=64,clip_range=0.1934,ent_coef=0.0000,gae_lambda=0.9085,gamma=0.9653,learning_rate=0.0004,n_steps=512\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00009_9_batch_size=64,clip_range=0.1934,ent_coef=0.0000,gae_lambda=0.9085,gamma=0.9653,learning_rate=0.0004,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205360.893607,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205484,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00009\",\n    \"date\": \"2025-11-03_15-31-24\",\n    \"time_this_iter_s\": 123.44886803627014,\n    \"time_total_s\": 123.44886803627014,\n    \"pid\": 95220,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0004067939702729457,\n      \"n_steps\": 512,\n      \"batch_size\": 64,\n      \"gamma\": 0.9652936011469091,\n      \"gae_lambda\": 0.9085335001277214,\n      \"clip_range\": 0.19340286146221553,\n      \"ent_coef\": 2.327857150979202e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 123.44886803627014,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_batch_size=64,clip_range=0.1934,ent_coef=0.0000,gae_lambda=0.9085,gamma=0.9653,learning_rate=0.0004,n_steps=512\"\n  },\n  \"last_result_time\": 1762205484.345077,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 123.44886803627014,\n      \"min\": 123.44886803627014,\n      \"avg\": 123.44886803627014,\n      \"last\": 123.44886803627014,\n      \"last-5-avg\": 123.44886803627014,\n      \"last-10-avg\": 123.44886803627014\n    },\n    \"time_total_s\": {\n      \"max\": 123.44886803627014,\n      \"min\": 123.44886803627014,\n      \"avg\": 123.44886803627014,\n      \"last\": 123.44886803627014,\n      \"last-5-avg\": 123.44886803627014,\n      \"last-10-avg\": 123.44886803627014\n    },\n    \"time_since_restore\": {\n      \"max\": 123.44886803627014,\n      \"min\": 123.44886803627014,\n      \"avg\": 123.44886803627014,\n      \"last\": 123.44886803627014,\n      \"last-5-avg\": 123.44886803627014,\n      \"last-10-avg\": 123.44886803627014\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405edcba41000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405edcba41000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405edcba41000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405edcba41000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405edcba41000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405edcba41000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00006\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030365f365f62617463685f73697a653d36342c636c69705f72616e67653d302e323038362c656e745f636f65663d302e303030302c6761655f6c616d6264613d302e393434342c67616d6d613d302e393634352c6c6561726e696e675f726174653d302e303030332c6e5f737465705f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00034712491508871756,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.9645110681334391,\n    \"gae_lambda\": 0.944392391020396,\n    \"clip_range\": 0.20857103320350492,\n    \"ent_coef\": 3.598293849494109e-05,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00034712491508871756,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.9645110681334391,\n    \"gae_lambda\": 0.944392391020396,\n    \"clip_range\": 0.20857103320350492,\n    \"ent_coef\": 3.598293849494109e-05,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00034712491508871756,\n    \"n_steps\": 1024,\n    \"batch_size\": 64,\n    \"gamma\": 0.9645110681334391,\n    \"gae_lambda\": 0.944392391020396,\n    \"clip_range\": 0.20857103320350492,\n    \"ent_coef\": 3.598293849494109e-05\n  },\n  \"experiment_tag\": \"6_batch_size=64,clip_range=0.2086,ent_coef=0.0000,gae_lambda=0.9444,gamma=0.9645,learning_rate=0.0003,n_steps=1024\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00006_6_batch_size=64,clip_range=0.2086,ent_coef=0.0000,gae_lambda=0.9444,gamma=0.9645,learning_rate=0.0003,n_step_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205238.5213928,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205355,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00006\",\n    \"date\": \"2025-11-03_15-29-15\",\n    \"time_this_iter_s\": 116.98978996276855,\n    \"time_total_s\": 116.98978996276855,\n    \"pid\": 95157,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00034712491508871756,\n      \"n_steps\": 1024,\n      \"batch_size\": 64,\n      \"gamma\": 0.9645110681334391,\n      \"gae_lambda\": 0.944392391020396,\n      \"clip_range\": 0.20857103320350492,\n      \"ent_coef\": 3.598293849494109e-05,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 116.98978996276855,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_batch_size=64,clip_range=0.2086,ent_coef=0.0000,gae_lambda=0.9444,gamma=0.9645,learning_rate=0.0003,n_steps=1024\"\n  },\n  \"last_result_time\": 1762205355.513727,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 116.98978996276855,\n      \"min\": 116.98978996276855,\n      \"avg\": 116.98978996276855,\n      \"last\": 116.98978996276855,\n      \"last-5-avg\": 116.98978996276855,\n      \"last-10-avg\": 116.98978996276855\n    },\n    \"time_total_s\": {\n      \"max\": 116.98978996276855,\n      \"min\": 116.98978996276855,\n      \"avg\": 116.98978996276855,\n      \"last\": 116.98978996276855,\n      \"last-5-avg\": 116.98978996276855,\n      \"last-10-avg\": 116.98978996276855\n    },\n    \"time_since_restore\": {\n      \"max\": 116.98978996276855,\n      \"min\": 116.98978996276855,\n      \"avg\": 116.98978996276855,\n      \"last\": 116.98978996276855,\n      \"last-5-avg\": 116.98978996276855,\n      \"last-10-avg\": 116.98978996276855\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d3f58b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d3f58b8000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d3f58b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d3f58b8000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405d3f58b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405d3f58b8000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_ppo\",\n  \"trial_id\": \"936d8_00002\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059517030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1d747261696e5f70706f5f323032352d31312d30335f31352d32352d3039948c0e747269616c5f6469725f6e616d65948c96747261696e5f70706f5f39333664385f30303030325f325f62617463685f73697a653d3132382c636c69705f72616e67653d302e313336302c656e745f636f65663d302e303030332c6761655f6c616d6264613d302e393632392c67616d6d613d302e393839332c6c6561726e696e675f726174653d302e303030322c6e5f7374655f323032352d31312d30335f31352d32352d3039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c232f55736572732f6672616e6b2f506172616d5f54756e652f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31312d30335f31352d32352d30399475622e\"\n  },\n  \"config\": {\n    \"learning_rate\": 0.00023306528390641684,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.9892617468398275,\n    \"gae_lambda\": 0.96290137887834,\n    \"clip_range\": 0.13600048275870635,\n    \"ent_coef\": 0.0003038535732876673,\n    \"total_timesteps\": 500000\n  },\n  \"_Trial__unresolved_config\": {\n    \"learning_rate\": 0.00023306528390641684,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.9892617468398275,\n    \"gae_lambda\": 0.96290137887834,\n    \"clip_range\": 0.13600048275870635,\n    \"ent_coef\": 0.0003038535732876673,\n    \"total_timesteps\": 500000\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00023306528390641684,\n    \"n_steps\": 256,\n    \"batch_size\": 128,\n    \"gamma\": 0.9892617468398275,\n    \"gae_lambda\": 0.96290137887834,\n    \"clip_range\": 0.13600048275870635,\n    \"ent_coef\": 0.0003038535732876673\n  },\n  \"experiment_tag\": \"2_batch_size=128,clip_range=0.1360,ent_coef=0.0003,gae_lambda=0.9629,gamma=0.9893,learning_rate=0.0002,n_steps=256\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"train_ppo_936d8_00002_2_batch_size=128,clip_range=0.1360,ent_coef=0.0003,gae_lambda=0.9629,gamma=0.9893,learning_rate=0.0002,n_ste_2025-11-03_15-25-09\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1762205111.26944,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_reward\": 500.0,\n    \"timestamp\": 1762205209,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"936d8_00002\",\n    \"date\": \"2025-11-03_15-26-49\",\n    \"time_this_iter_s\": 98.03967308998108,\n    \"time_total_s\": 98.03967308998108,\n    \"pid\": 95094,\n    \"hostname\": \"FrankBook.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00023306528390641684,\n      \"n_steps\": 256,\n      \"batch_size\": 128,\n      \"gamma\": 0.9892617468398275,\n      \"gae_lambda\": 0.96290137887834,\n      \"clip_range\": 0.13600048275870635,\n      \"ent_coef\": 0.0003038535732876673,\n      \"total_timesteps\": 500000\n    },\n    \"time_since_restore\": 98.03967308998108,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_batch_size=128,clip_range=0.1360,ent_coef=0.0003,gae_lambda=0.9629,gamma=0.9893,learning_rate=0.0002,n_steps=256\"\n  },\n  \"last_result_time\": 1762205209.312902,\n  \"metric_analysis\": {\n    \"mean_reward\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 98.03967308998108,\n      \"min\": 98.03967308998108,\n      \"avg\": 98.03967308998108,\n      \"last\": 98.03967308998108,\n      \"last-5-avg\": 98.03967308998108,\n      \"last-10-avg\": 98.03967308998108\n    },\n    \"time_total_s\": {\n      \"max\": 98.03967308998108,\n      \"min\": 98.03967308998108,\n      \"avg\": 98.03967308998108,\n      \"last\": 98.03967308998108,\n      \"last-5-avg\": 98.03967308998108,\n      \"last-10-avg\": 98.03967308998108\n    },\n    \"time_since_restore\": {\n      \"max\": 98.03967308998108,\n      \"min\": 98.03967308998108,\n      \"avg\": 98.03967308998108,\n      \"last\": 98.03967308998108,\n      \"last-5-avg\": 98.03967308998108,\n      \"last-10-avg\": 98.03967308998108\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_reward\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407f400000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407f400000000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058828a01000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058828a01000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058828a01000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058828a01000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474058828a01000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474058828a01000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 391212.917719958, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": "mean_reward", "_total_time": 2957.6048221588135, "_iteration": 3817, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1762205109.826603, "_session_str": "2025-11-03_15-25-09", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1762205109.826603}}